{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credits to Elissaios Sarmas for the model training and transfer learning code, which was adapted for use on this dataset. Code can be found here: https://github.com/ElissaiosSarmas/Transfer-learning-strategies-for-solar-power-forecasting-under-data-scarcity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -r ./LSTM/logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use a dataset obtained from Kaggle (credits to Afroz) that has 8760 entries and contains hourly PV output to train the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import datetime, os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.metrics import MeanAbsoluteError, RootMeanSquaredError\n",
    "from keras_layer_normalization import LayerNormalization\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow import keras\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import shuffle\n",
    "from hyperopt import fmin, tpe, hp, partial, Trials, STATUS_OK, STATUS_FAIL, space_eval\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold, cross_val_score \n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error, zero_one_loss,mean_absolute_error,r2_score\n",
    "pd.options.mode.chained_assignment = None\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/work/Honours code/Datasets/Kaggle-Solar-PV-data/Solar Power Plant Data.csv\"\n",
    "\n",
    "p0 = pd.read_csv(path, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0_copy = p0.copy()\n",
    "p0_copy['timestamp'] = pd.to_datetime(p0['Date-Hour(NMT)'], format='%d.%m.%Y-%H:%M')\n",
    "\n",
    "p0_copy.drop(['Date-Hour(NMT)'], axis=1, inplace=True)\n",
    "\n",
    "timestamp = p0_copy.pop('timestamp')\n",
    "p0_copy.insert(0, 'timestamp', timestamp)\n",
    "p0_copy['hour'] = pd.to_datetime(p0_copy['timestamp']).dt.hour\n",
    "p0_copy['month'] = pd.to_datetime(p0_copy['timestamp']).dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>AirPressure</th>\n",
       "      <th>Radiation</th>\n",
       "      <th>AirTemperature</th>\n",
       "      <th>RelativeAirHumidity</th>\n",
       "      <th>SystemProduction</th>\n",
       "      <th>hour</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1003.8</td>\n",
       "      <td>-7.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01 01:00:00</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1003.5</td>\n",
       "      <td>-7.4</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01 02:00:00</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1003.4</td>\n",
       "      <td>-6.7</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01 03:00:00</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1003.3</td>\n",
       "      <td>-7.2</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01 04:00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1003.1</td>\n",
       "      <td>-6.3</td>\n",
       "      <td>3.6</td>\n",
       "      <td>67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  WindSpeed  Sunshine  AirPressure  Radiation  \\\n",
       "0 2017-01-01 00:00:00        0.6         0       1003.8       -7.4   \n",
       "1 2017-01-01 01:00:00        1.7         0       1003.5       -7.4   \n",
       "2 2017-01-01 02:00:00        0.6         0       1003.4       -6.7   \n",
       "3 2017-01-01 03:00:00        2.4         0       1003.3       -7.2   \n",
       "4 2017-01-01 04:00:00        4.0         0       1003.1       -6.3   \n",
       "\n",
       "   AirTemperature  RelativeAirHumidity  SystemProduction  hour  month  \n",
       "0             0.1                   97               0.0     0      1  \n",
       "1            -0.2                   98               0.0     1      1  \n",
       "2            -1.2                   99               0.0     2      1  \n",
       "3            -1.3                   99               0.0     3      1  \n",
       "4             3.6                   67               0.0     4      1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p0_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = p0_copy.corr()\n",
    "# Plot the correlation matrix\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Dataset = 8760\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Perform One-Hot-Encoding for Months and Sin-Cos Similarities for Hours\n",
    "data = p0_copy\n",
    "data['timestamp'] = pd.to_numeric(data['timestamp'])\n",
    "data = pd.get_dummies(data, columns=['month'])\n",
    "data.loc[:,'sin_hour'] = np.sin(2*np.pi*data['timestamp']/24)\n",
    "data.loc[:,'cos_hour'] = np.cos(2*np.pi*data['timestamp']/24)\n",
    "\n",
    "print(\"Total Dataset =\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shaping data for LSTM input\n",
    "def split_sequences(sequences, n_steps, n_outputs, only_production, validation_split):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern \n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix + n_outputs > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        if only_production==True:\n",
    "            seq_x, seq_y = sequences[i:end_ix, -1], sequences[end_ix:(end_ix+n_outputs), -1]\n",
    "        else:\n",
    "            seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:(end_ix+n_outputs), -1]\n",
    "            \n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    \n",
    "    # Split the data into training and validation sets\n",
    "    x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=validation_split, random_state=42)\n",
    "    \n",
    "    return x_train, x_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_shapes(x, y, lag_, n_features_, num_of_outputs_, only_production, validation_split):\n",
    "    unique_shapes = []\n",
    "    for k in range(len(x)):\n",
    "        if only_production==True:\n",
    "            if (x[k].shape == (lag,)) & (y[k].shape == (num_of_outputs_,)):\n",
    "                unique_shapes.append(k)\n",
    "        else:\n",
    "            if (x[k].shape == (lag_, n_features_)) & (y[k].shape == (num_of_outputs_,)):\n",
    "                unique_shapes.append(k)       \n",
    "    x = x[unique_shapes]\n",
    "    y = y[unique_shapes]\n",
    "    x = np.stack(x)\n",
    "    y = np.stack(y)\n",
    "    \n",
    "    # Split the data into training and validation sets\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=validation_split, random_state=42)\n",
    "    \n",
    "    return x_train, x_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns that you want to use as features\n",
    "cols = [\n",
    "    \"timestamp\",\n",
    "    \"WindSpeed\",\n",
    "    \"Sunshine\",\n",
    "    \"AirPressure\",\n",
    "    \"Radiation\",\n",
    "    \"AirTemperature\",\n",
    "    \"RelativeAirHumidity\",\n",
    "    \"sin_hour\",\n",
    "    \"cos_hour\",\n",
    "    \"SystemProduction\",\n",
    "    ]\n",
    "# Set to True if using only the production, else to False\n",
    "only_production = False\n",
    "# Splitting factor for training set and test set\n",
    "split = 0.8\n",
    "\n",
    "# Select the lag variable, the number of features (must be same with cols selected) and the horizon\n",
    "lag = 5\n",
    "n_features = len(cols)\n",
    "num_of_outputs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data seperately\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "if only_production == True:\n",
    "    data_ = data_['SystemProduction']\n",
    "    train = data_.iloc[:int(len(data_)*split_),]\n",
    "    test = data_.iloc[int(len(data_)*split_):,]\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    train = scaler.fit_transform(train.values.reshape(-1, 1))\n",
    "    test = scaler.fit_transform(test.values.reshape(-1, 1))\n",
    "else:\n",
    "    data = data[cols]\n",
    "    train = data.iloc[:int(len(data)*split),:]\n",
    "    test = data.iloc[int(len(data)*split):,]\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    train = scaler.fit_transform(train)\n",
    "    test = scaler.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Train / Test = (280, 5, 10) (280, 1) (69, 5, 10) (69, 1)\n"
     ]
    }
   ],
   "source": [
    "# Create the input for LSTM: x(batch_size, lag, features), y(batch_size,)\n",
    "\n",
    "x_train, x_val, y_train, y_val = split_sequences(train, n_steps=lag, n_outputs=num_of_outputs, only_production=only_production, validation_split=split)\n",
    "x_test, x_val, y_test, y_val = split_sequences(test, n_steps=lag, n_outputs=num_of_outputs, only_production=only_production, validation_split=split)\n",
    "\n",
    "x_train, x_val, y_train, y_val = unique_shapes(x_train, y_train, lag, n_features, num_of_outputs, only_production=only_production, validation_split=split)\n",
    "x_test, x_val, y_test, y_val = unique_shapes(x_test, y_test, lag, n_features, num_of_outputs, only_production=only_production, validation_split=split)\n",
    "\n",
    "# Reshape for only_production case\n",
    "if only_production:\n",
    "    x_train = x_train.reshape((x_train.shape[0], lag, 1))\n",
    "    x_test = x_test.reshape((x_test.shape[0], lag, 1))\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2])\n",
    "# Print the shapes\n",
    "print(\"Size of Train / Test =\", x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_error(actual, predicted):\n",
    "    res = np.empty(actual.shape)\n",
    "    for j in range(actual.shape[0]):\n",
    "        if actual[j] != 0:\n",
    "            res[j] = (actual[j] - predicted[j]) / actual[j]\n",
    "        else:\n",
    "            res[j] = predicted[j] / np.mean(actual)\n",
    "    return res\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs(percentage_error(np.asarray(y_true), np.asarray(y_pred))))\n",
    "\n",
    "def createModel():\n",
    "\n",
    "    # LSTM Model Architecture\n",
    "\n",
    "    optimizer = Adam(learning_rate=0.002, clipvalue=0.5)\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(32,\n",
    "                                 activation=\"relu\",\n",
    "                                 return_sequences=True),\n",
    "                                input_shape=(x_train.shape[1], x_train.shape[2]), name = 'bidirectional_1'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Bidirectional(LSTM(128,activation=\"relu\",return_sequences=True), name = 'bidirectional_2'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Bidirectional(LSTM(256,activation=\"relu\",return_sequences=False), name = 'bidirectional_3'))\n",
    "    model.add(Dense(1, name='output_layer'))\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mae'])\n",
    "\n",
    "    # renaming weight handles to ensure uniqueness\n",
    "    # credits to Nour Alden\n",
    "    # from https://stackoverflow.com/questions/72776335/valueerror-unable-to-create-dataset-name-already-exists-when-using-modelcheck\n",
    "\n",
    "    for i in range(len(model.weights)):\n",
    "        model.weights[i]._handle_name = model.weights[i].name + \"_\" + str(i)\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from keras.layers import TFSMLayer\n",
    "import h5py\n",
    "import os\n",
    "import time\n",
    "timestamp = int(time.time())\n",
    "true_values = []\n",
    "predicted_values = []\n",
    "#model_path = \"C:/work/Honours code/Transfer learning/LSTM/model/LSTM_base.h5\"\n",
    "model_path = \"model/LSTM_base.h5\"\n",
    "def fit_predict_stats(model):\n",
    "    # Early stopping property\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "    tb = TensorBoard(log_dir='logs')\n",
    "    logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "    history = model.fit(x_train, y_train, epochs=100, validation_split=0.14, batch_size=32, verbose=1, shuffle=True, callbacks=[tensorboard_callback, es]).history\n",
    "   \n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        \n",
    "    # Load the model\n",
    "        tf.debugging.set_log_device_placement(True)\n",
    "        model = load_model(model_path)\n",
    "    else:\n",
    "        # Model file does not exist, so save the model\n",
    "        \n",
    "        # Fit the model\n",
    "        model.save(model_path, overwrite=True)\n",
    "\n",
    "\n",
    "\n",
    "    # summarize history for MAE and MSE\n",
    "    # plt.plot(history['loss'])\n",
    "    # plt.plot(history['val_loss'])\n",
    "    # plt.title('model loss')\n",
    "    # plt.ylabel('Model MSE')\n",
    "    # plt.xlabel('epoch')\n",
    "    # plt.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "    # plt.figure()\n",
    "    # plt.plot(history['mae'])\n",
    "    # plt.plot(history['val_mae'])\n",
    "    # plt.title('Model MAE')\n",
    "    # plt.ylabel('MAE')\n",
    "    # plt.xlabel('epoch')\n",
    "    # plt.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "    # Metrics on scaled data\n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    y_pred = model.predict(x_train)\n",
    "    rmse = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "    mae = mean_absolute_error(y_train, y_pred)\n",
    "    # print('Train Scaled RMSE: {}'.format(rmse))\n",
    "    # print('Train Scaled MAE: {}'.format(mae))\n",
    "    # print('Train Scaled R2 Score: ', r2_score(y_train, y_pred)*100)\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    # print('Test Scaled RMSE: {}'.format(rmse))\n",
    "    # print('Test Scaled MAE: {}'.format(mae))\n",
    "    # print('Test Scaled R2 Score: ',r2_score(y_test, y_pred)*100)\n",
    "\n",
    "\n",
    "    \n",
    "    # Metrics on original data\n",
    "    true = []\n",
    "    hat = []\n",
    "    range_ = [0]\n",
    "    # range_ = list(range(6))\n",
    "\n",
    "    for i,j in zip([[x_train,y_train],[x_test,y_test]],['Train','Test']):\n",
    "        # make a prediction\n",
    "        yhat = model.predict(i[0])\n",
    "        if yhat.shape == (yhat.shape[0],):\n",
    "            yhat = yhat.reshape((yhat.shape[0],1))  \n",
    "      \n",
    "        y_hat = []\n",
    "        for k in range(len(yhat)):\n",
    "            if k == 0:\n",
    "                for l in range_:\n",
    "                    y_hat.append(yhat[k,l])\n",
    "            else:\n",
    "                y_hat.append(yhat[k,-1])\n",
    "        \n",
    "        y_hat = np.stack(y_hat)\n",
    "        y_hat = y_hat.reshape((y_hat.shape[0],1))\n",
    "        \n",
    "        i[0] = i[0].reshape((i[0].shape[0],lag,n_features))\n",
    "        \n",
    "        x_hat = []\n",
    "        for k in range(len(i[0])):\n",
    "            if k == 0:\n",
    "                x_hat.append(i[0][k])\n",
    "            elif k!= 0:\n",
    "                x_hat.append(i[0][k][-1,:])\n",
    "        \n",
    "        x_hat = np.vstack(x_hat)\n",
    "        \n",
    "        initial_x_hat_shape = x_hat.shape[0]\n",
    "        initial_y_hat_shape = y_hat.shape[0]\n",
    "        \n",
    "        # print(x_hat.shape)\n",
    "        # print(y_hat.shape)\n",
    "        \n",
    "        if x_hat.shape[0]-y_hat.shape[0] != 0.0:\n",
    "            if x_hat.shape[0] > y_hat.shape[0]:\n",
    "                for k in range(x_hat.shape[0]-y_hat.shape[0]):\n",
    "                    y_hat = np.insert(y_hat, 0, y_hat[0,0], axis=0)\n",
    "                    added_values = True\n",
    "            elif x_hat.shape[0] < y_hat.shape[0]:\n",
    "                y_hat = y_hat[-int(x_hat.shape[0]-y_hat.shape[0]):,:]\n",
    "                added_values = False\n",
    "        \n",
    "        # print(x_hat.shape)\n",
    "        # print(y_hat.shape)\n",
    "        \n",
    "        # invert scaling for forecast\n",
    "        if only_production==True:\n",
    "            inv_yhat = np.concatenate((x_hat[:,:-1],y_hat), axis=1)\n",
    "            inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "        else:    \n",
    "            inv_yhat = np.concatenate((x_hat[:,:-1],y_hat), axis=1)\n",
    "            inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "            inv_yhat = inv_yhat[:,-1]\n",
    "            \n",
    "        # invert scaling for actual\n",
    "        y_true = []\n",
    "        for k in range(len(i[1])):\n",
    "            if k ==0:\n",
    "                for l in range_:\n",
    "                    y_true.append(i[1][k,l])\n",
    "            else:\n",
    "                y_true.append(i[1][k,-1])\n",
    "\n",
    "        y_true = np.stack(y_true)\n",
    "        y_true = y_true.reshape((y_true.shape[0],1))\n",
    "        print(y_true.shape)\n",
    "\n",
    "        initial_y_true_shape = y_true.shape[0]\n",
    "        \n",
    "        if x_hat.shape[0]-y_true.shape[0] != 0.0:\n",
    "            if x_hat.shape[0] > y_true.shape[0]:\n",
    "                for k in range(x_hat.shape[0]-y_true.shape[0]):\n",
    "                    y_true = np.insert(y_true, 0, y_true[0,0], axis=0)\n",
    "                    added_values = True\n",
    "            elif x_hat.shape[0] < y_true.shape[0]:\n",
    "                y_true = y_true[-int(x_hat.shape[0]-y_true.shape[0]):,:]\n",
    "                added_values = False\n",
    "                \n",
    "        if only_production==True:\n",
    "            inv_y = np.concatenate((x_hat[:,:-1],y_true), axis=1)\n",
    "            inv_y = scaler.inverse_transform(inv_y)\n",
    "        else:\n",
    "            inv_y = np.concatenate((x_hat[:,:-1],y_true), axis=1)\n",
    "            inv_y = scaler.inverse_transform(inv_y)\n",
    "            inv_y = inv_y[:,-1]\n",
    "        \n",
    "        true.append(inv_y)\n",
    "        hat.append(inv_yhat)\n",
    "\n",
    "        # true_values.append(true)\n",
    "        # predicted_values.append(hat)\n",
    "        \n",
    "        # calculate RMSE\n",
    "        rmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "        print('Test RMSE: %.3f' % rmse)\n",
    "        # calculate MAE\n",
    "        mae = mean_absolute_error(inv_y, inv_yhat)\n",
    "        print('Test MAE: %.3f' % mae)\n",
    "        # calculate R2\n",
    "        r2 = r2_score(inv_y, inv_yhat)\n",
    "        print('Test R2 Score: ',r2)\n",
    "        # Calculate MAPE\n",
    "        mape = mean_absolute_percentage_error(inv_y, inv_yhat)\n",
    "        print('MAPE', mape)\n",
    "        # Calculate MBE\n",
    "        mbe = np.mean(inv_yhat - inv_y)\n",
    "        print('Test MBE', mbe)\n",
    "        # Calculate nRMSE\n",
    "        nRMSE = rmse / np.mean(inv_y)\n",
    "        print('nRMSE', nRMSE)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    mae_list.append(mae)\n",
    "    rmse_list.append(rmse)\n",
    "    r_square_list.append(r2)\n",
    "    mape_list.append(mape)\n",
    "    mbe_list.append(mbe)\n",
    "    nRMSE_list.append(nRMSE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 410ms/step - loss: 0.0652 - mae: 0.1856 - val_loss: 0.0384 - val_mae: 0.1013\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0321 - mae: 0.1065 - val_loss: 0.0237 - val_mae: 0.1053\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0293 - mae: 0.1182 - val_loss: 0.0283 - val_mae: 0.0891\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0293 - mae: 0.0968 - val_loss: 0.0217 - val_mae: 0.0981\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0322 - mae: 0.1171 - val_loss: 0.0216 - val_mae: 0.0835\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0266 - mae: 0.0975 - val_loss: 0.0179 - val_mae: 0.0799\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0260 - mae: 0.1001 - val_loss: 0.0177 - val_mae: 0.0779\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0191 - mae: 0.0800 - val_loss: 0.0175 - val_mae: 0.0756\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0214 - mae: 0.0856 - val_loss: 0.0163 - val_mae: 0.0788\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0219 - mae: 0.0964 - val_loss: 0.0146 - val_mae: 0.0704\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0180 - mae: 0.0742 - val_loss: 0.0132 - val_mae: 0.0666\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0118 - mae: 0.0666 - val_loss: 0.0127 - val_mae: 0.0750\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0173 - mae: 0.0829 - val_loss: 0.0157 - val_mae: 0.0686\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0127 - mae: 0.0630 - val_loss: 0.0114 - val_mae: 0.0652\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0094 - mae: 0.0605 - val_loss: 0.0104 - val_mae: 0.0635\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0129 - mae: 0.0703 - val_loss: 0.0187 - val_mae: 0.0718\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0200 - mae: 0.0806 - val_loss: 0.0172 - val_mae: 0.0717\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0128 - mae: 0.0562 - val_loss: 0.0125 - val_mae: 0.0660\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0107 - mae: 0.0624 - val_loss: 0.0141 - val_mae: 0.0656\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0106 - mae: 0.0631 - val_loss: 0.0133 - val_mae: 0.0634\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0081 - mae: 0.0512 - val_loss: 0.0122 - val_mae: 0.0636\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0083 - mae: 0.0501 - val_loss: 0.0120 - val_mae: 0.0644\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0082 - mae: 0.0528 - val_loss: 0.0134 - val_mae: 0.0681\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0121 - mae: 0.0658 - val_loss: 0.0186 - val_mae: 0.0747\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0081 - mae: 0.0512 - val_loss: 0.0155 - val_mae: 0.0735\n",
      "Epoch 25: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 172ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "(280, 1)\n",
      "Test RMSE: 497.139\n",
      "Test MAE: 297.643\n",
      "Test R2 Score:  0.7146922327935914\n",
      "MAPE 0.7815068375148831\n",
      "Test MBE 197.00339033497963\n",
      "nRMSE 0.9500050519951583\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "(69, 1)\n",
      "Test RMSE: 264.876\n",
      "Test MAE: 170.215\n",
      "Test R2 Score:  0.10674379106995568\n",
      "MAPE 1.9750164998249322\n",
      "Test MBE 118.60806558997352\n",
      "nRMSE 3.14738266588095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 415ms/step - loss: 0.0498 - mae: 0.1548 - val_loss: 0.0336 - val_mae: 0.1024\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0330 - mae: 0.1236 - val_loss: 0.0213 - val_mae: 0.0901\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0299 - mae: 0.1027 - val_loss: 0.0203 - val_mae: 0.0861\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 155ms/step - loss: 0.0220 - mae: 0.0948 - val_loss: 0.0214 - val_mae: 0.0838\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0232 - mae: 0.0863 - val_loss: 0.0189 - val_mae: 0.0849\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 173ms/step - loss: 0.0234 - mae: 0.1041 - val_loss: 0.0233 - val_mae: 0.0823\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0245 - mae: 0.0882 - val_loss: 0.0179 - val_mae: 0.0810\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 176ms/step - loss: 0.0254 - mae: 0.0933 - val_loss: 0.0183 - val_mae: 0.0754\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0183 - mae: 0.0841 - val_loss: 0.0165 - val_mae: 0.0731\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0149 - mae: 0.0686 - val_loss: 0.0149 - val_mae: 0.0708\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0160 - mae: 0.0790 - val_loss: 0.0133 - val_mae: 0.0688\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0113 - mae: 0.0623 - val_loss: 0.0132 - val_mae: 0.0629\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0136 - mae: 0.0698 - val_loss: 0.0119 - val_mae: 0.0625\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0115 - mae: 0.0649 - val_loss: 0.0256 - val_mae: 0.0781\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0192 - mae: 0.0775 - val_loss: 0.0197 - val_mae: 0.0707\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step - loss: 0.0164 - mae: 0.0678 - val_loss: 0.0142 - val_mae: 0.0721\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0126 - mae: 0.0705 - val_loss: 0.0163 - val_mae: 0.0695\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0120 - mae: 0.0607 - val_loss: 0.0133 - val_mae: 0.0695\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0127 - mae: 0.0700 - val_loss: 0.0147 - val_mae: 0.0663\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0112 - mae: 0.0643 - val_loss: 0.0153 - val_mae: 0.0669\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0094 - mae: 0.0564 - val_loss: 0.0123 - val_mae: 0.0654\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 179ms/step - loss: 0.0100 - mae: 0.0569 - val_loss: 0.0128 - val_mae: 0.0665\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0100 - mae: 0.0605 - val_loss: 0.0148 - val_mae: 0.0687\n",
      "Epoch 23: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "(280, 1)\n",
      "Test RMSE: 497.139\n",
      "Test MAE: 297.643\n",
      "Test R2 Score:  0.7146922327935914\n",
      "MAPE 0.7815068375148831\n",
      "Test MBE 197.00339033497963\n",
      "nRMSE 0.9500050519951583\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "(69, 1)\n",
      "Test RMSE: 264.876\n",
      "Test MAE: 170.215\n",
      "Test R2 Score:  0.10674379106995568\n",
      "MAPE 1.9750164998249322\n",
      "Test MBE 118.60806558997352\n",
      "nRMSE 3.14738266588095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 307ms/step - loss: 0.0558 - mae: 0.1581 - val_loss: 0.0352 - val_mae: 0.1154\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0417 - mae: 0.1535 - val_loss: 0.0266 - val_mae: 0.0898\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0248 - mae: 0.0944 - val_loss: 0.0237 - val_mae: 0.0878\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0316 - mae: 0.1090 - val_loss: 0.0253 - val_mae: 0.0862\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0230 - mae: 0.0924 - val_loss: 0.0207 - val_mae: 0.0976\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0233 - mae: 0.1025 - val_loss: 0.0198 - val_mae: 0.0824\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0219 - mae: 0.0882 - val_loss: 0.0182 - val_mae: 0.0830\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0194 - mae: 0.0849 - val_loss: 0.0189 - val_mae: 0.0806\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0214 - mae: 0.0922 - val_loss: 0.0183 - val_mae: 0.0758\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0190 - mae: 0.0770 - val_loss: 0.0169 - val_mae: 0.0771\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0155 - mae: 0.0722 - val_loss: 0.0190 - val_mae: 0.0917\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0190 - mae: 0.0892 - val_loss: 0.0193 - val_mae: 0.0750\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0203 - mae: 0.0884 - val_loss: 0.0158 - val_mae: 0.0749\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0141 - mae: 0.0692 - val_loss: 0.0155 - val_mae: 0.0767\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0157 - mae: 0.0798 - val_loss: 0.0162 - val_mae: 0.0756\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0173 - mae: 0.0804 - val_loss: 0.0149 - val_mae: 0.0704\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0122 - mae: 0.0623 - val_loss: 0.0131 - val_mae: 0.0675\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0104 - mae: 0.0579 - val_loss: 0.0128 - val_mae: 0.0684\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0103 - mae: 0.0650 - val_loss: 0.0170 - val_mae: 0.0720\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0137 - mae: 0.0648 - val_loss: 0.0138 - val_mae: 0.0704\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0106 - mae: 0.0581 - val_loss: 0.0145 - val_mae: 0.0696\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0094 - mae: 0.0573 - val_loss: 0.0131 - val_mae: 0.0648\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0102 - mae: 0.0570 - val_loss: 0.0115 - val_mae: 0.0657\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0075 - mae: 0.0552 - val_loss: 0.0162 - val_mae: 0.0706\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0104 - mae: 0.0581 - val_loss: 0.0146 - val_mae: 0.0686\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0078 - mae: 0.0510 - val_loss: 0.0138 - val_mae: 0.0676\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0094 - mae: 0.0599 - val_loss: 0.0134 - val_mae: 0.0657\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0071 - mae: 0.0491 - val_loss: 0.0141 - val_mae: 0.0684\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0096 - mae: 0.0619 - val_loss: 0.0156 - val_mae: 0.0728\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0081 - mae: 0.0537 - val_loss: 0.0165 - val_mae: 0.0683\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0069 - mae: 0.0455 - val_loss: 0.0114 - val_mae: 0.0620\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0071 - mae: 0.0487 - val_loss: 0.0132 - val_mae: 0.0694\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0088 - mae: 0.0541 - val_loss: 0.0164 - val_mae: 0.0722\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0074 - mae: 0.0516 - val_loss: 0.0124 - val_mae: 0.0622\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0067 - mae: 0.0471 - val_loss: 0.0150 - val_mae: 0.0689\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0074 - mae: 0.0514 - val_loss: 0.0168 - val_mae: 0.0714\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0059 - mae: 0.0435 - val_loss: 0.0119 - val_mae: 0.0614\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0082 - mae: 0.0515 - val_loss: 0.0155 - val_mae: 0.0694\n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0068 - mae: 0.0492 - val_loss: 0.0185 - val_mae: 0.0705\n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0091 - mae: 0.0514 - val_loss: 0.0119 - val_mae: 0.0642\n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0078 - mae: 0.0523 - val_loss: 0.0130 - val_mae: 0.0658\n",
      "Epoch 41: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 352ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "(280, 1)\n",
      "Test RMSE: 497.139\n",
      "Test MAE: 297.643\n",
      "Test R2 Score:  0.7146922327935914\n",
      "MAPE 0.7815068375148831\n",
      "Test MBE 197.00339033497963\n",
      "nRMSE 0.9500050519951583\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "(69, 1)\n",
      "Test RMSE: 264.876\n",
      "Test MAE: 170.215\n",
      "Test R2 Score:  0.10674379106995568\n",
      "MAPE 1.9750164998249322\n",
      "Test MBE 118.60806558997352\n",
      "nRMSE 3.14738266588095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 254ms/step - loss: 0.0463 - mae: 0.1479 - val_loss: 0.0312 - val_mae: 0.1029\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0258 - mae: 0.1106 - val_loss: 0.0232 - val_mae: 0.0871\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 159ms/step - loss: 0.0291 - mae: 0.0987 - val_loss: 0.0204 - val_mae: 0.0855\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0229 - mae: 0.1017 - val_loss: 0.0193 - val_mae: 0.0853\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0267 - mae: 0.1070 - val_loss: 0.0195 - val_mae: 0.0794\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0262 - mae: 0.1048 - val_loss: 0.0194 - val_mae: 0.0758\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0245 - mae: 0.0853 - val_loss: 0.0187 - val_mae: 0.0795\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0208 - mae: 0.0842 - val_loss: 0.0168 - val_mae: 0.0722\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - loss: 0.0182 - mae: 0.0798 - val_loss: 0.0160 - val_mae: 0.0707\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0139 - mae: 0.0646 - val_loss: 0.0172 - val_mae: 0.0878\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0199 - mae: 0.0903 - val_loss: 0.0138 - val_mae: 0.0688\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0135 - mae: 0.0646 - val_loss: 0.0137 - val_mae: 0.0683\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0108 - mae: 0.0614 - val_loss: 0.0140 - val_mae: 0.0634\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0199 - mae: 0.0743 - val_loss: 0.0185 - val_mae: 0.0683\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0181 - mae: 0.0728 - val_loss: 0.0160 - val_mae: 0.0815\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0151 - mae: 0.0759 - val_loss: 0.0153 - val_mae: 0.0694\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0102 - mae: 0.0550 - val_loss: 0.0129 - val_mae: 0.0667\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0116 - mae: 0.0590 - val_loss: 0.0169 - val_mae: 0.0663\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0102 - mae: 0.0603 - val_loss: 0.0117 - val_mae: 0.0639\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0104 - mae: 0.0587 - val_loss: 0.0138 - val_mae: 0.0622\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0119 - mae: 0.0602 - val_loss: 0.0113 - val_mae: 0.0671\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0094 - mae: 0.0560 - val_loss: 0.0108 - val_mae: 0.0644\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0088 - mae: 0.0552 - val_loss: 0.0157 - val_mae: 0.0644\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0094 - mae: 0.0539 - val_loss: 0.0118 - val_mae: 0.0668\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0085 - mae: 0.0570 - val_loss: 0.0119 - val_mae: 0.0630\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0097 - mae: 0.0540 - val_loss: 0.0119 - val_mae: 0.0648\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0092 - mae: 0.0588 - val_loss: 0.0217 - val_mae: 0.0711\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0134 - mae: 0.0619 - val_loss: 0.0137 - val_mae: 0.0732\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0123 - mae: 0.0666 - val_loss: 0.0165 - val_mae: 0.0680\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0097 - mae: 0.0564 - val_loss: 0.0128 - val_mae: 0.0672\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0087 - mae: 0.0520 - val_loss: 0.0127 - val_mae: 0.0681\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0087 - mae: 0.0543 - val_loss: 0.0139 - val_mae: 0.0687\n",
      "Epoch 32: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 189ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "(280, 1)\n",
      "Test RMSE: 497.139\n",
      "Test MAE: 297.643\n",
      "Test R2 Score:  0.7146922327935914\n",
      "MAPE 0.7815068375148831\n",
      "Test MBE 197.00339033497963\n",
      "nRMSE 0.9500050519951583\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "(69, 1)\n",
      "Test RMSE: 264.876\n",
      "Test MAE: 170.215\n",
      "Test R2 Score:  0.10674379106995568\n",
      "MAPE 1.9750164998249322\n",
      "Test MBE 118.60806558997352\n",
      "nRMSE 3.14738266588095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 418ms/step - loss: 0.0568 - mae: 0.1663 - val_loss: 0.0431 - val_mae: 0.1078\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0576 - mae: 0.1517 - val_loss: 0.0259 - val_mae: 0.1245\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0279 - mae: 0.1295 - val_loss: 0.0220 - val_mae: 0.0892\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0341 - mae: 0.1136 - val_loss: 0.0230 - val_mae: 0.0856\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0247 - mae: 0.0952 - val_loss: 0.0191 - val_mae: 0.0882\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0229 - mae: 0.0999 - val_loss: 0.0199 - val_mae: 0.0814\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0214 - mae: 0.0885 - val_loss: 0.0177 - val_mae: 0.0793\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0216 - mae: 0.0955 - val_loss: 0.0182 - val_mae: 0.0756\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0192 - mae: 0.0828 - val_loss: 0.0183 - val_mae: 0.0855\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0192 - mae: 0.0870 - val_loss: 0.0174 - val_mae: 0.0739\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - loss: 0.0186 - mae: 0.0795 - val_loss: 0.0184 - val_mae: 0.0732\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0232 - mae: 0.0794 - val_loss: 0.0168 - val_mae: 0.0748\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0218 - mae: 0.0953 - val_loss: 0.0182 - val_mae: 0.0767\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0229 - mae: 0.0855 - val_loss: 0.0179 - val_mae: 0.0764\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0149 - mae: 0.0730 - val_loss: 0.0147 - val_mae: 0.0750\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0146 - mae: 0.0744 - val_loss: 0.0152 - val_mae: 0.0703\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0120 - mae: 0.0648 - val_loss: 0.0154 - val_mae: 0.0782\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0127 - mae: 0.0756 - val_loss: 0.0142 - val_mae: 0.0683\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0110 - mae: 0.0560 - val_loss: 0.0139 - val_mae: 0.0721\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0146 - mae: 0.0777 - val_loss: 0.0162 - val_mae: 0.0677\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0099 - mae: 0.0570 - val_loss: 0.0157 - val_mae: 0.0744\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0148 - mae: 0.0739 - val_loss: 0.0147 - val_mae: 0.0692\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - loss: 0.0098 - mae: 0.0610 - val_loss: 0.0118 - val_mae: 0.0639\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0097 - mae: 0.0541 - val_loss: 0.0121 - val_mae: 0.0668\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0093 - mae: 0.0612 - val_loss: 0.0112 - val_mae: 0.0638\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0098 - mae: 0.0571 - val_loss: 0.0112 - val_mae: 0.0643\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 371ms/step - loss: 0.0103 - mae: 0.0590 - val_loss: 0.0121 - val_mae: 0.0647\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0094 - mae: 0.0598 - val_loss: 0.0159 - val_mae: 0.0681\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0105 - mae: 0.0553 - val_loss: 0.0149 - val_mae: 0.0702\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0098 - mae: 0.0631 - val_loss: 0.0173 - val_mae: 0.0717\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0121 - mae: 0.0554 - val_loss: 0.0136 - val_mae: 0.0696\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0115 - mae: 0.0663 - val_loss: 0.0133 - val_mae: 0.0640\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0094 - mae: 0.0547 - val_loss: 0.0123 - val_mae: 0.0659\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0090 - mae: 0.0566 - val_loss: 0.0111 - val_mae: 0.0639\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0073 - mae: 0.0467 - val_loss: 0.0129 - val_mae: 0.0649\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0055 - mae: 0.0439 - val_loss: 0.0130 - val_mae: 0.0672\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0089 - mae: 0.0603 - val_loss: 0.0157 - val_mae: 0.0686\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0107 - mae: 0.0601 - val_loss: 0.0115 - val_mae: 0.0654\n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0092 - mae: 0.0548 - val_loss: 0.0158 - val_mae: 0.0710\n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0087 - mae: 0.0608 - val_loss: 0.0136 - val_mae: 0.0665\n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0074 - mae: 0.0486 - val_loss: 0.0130 - val_mae: 0.0705\n",
      "Epoch 42/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0070 - mae: 0.0508 - val_loss: 0.0135 - val_mae: 0.0729\n",
      "Epoch 43/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0077 - mae: 0.0573 - val_loss: 0.0140 - val_mae: 0.0673\n",
      "Epoch 44/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0072 - mae: 0.0476 - val_loss: 0.0142 - val_mae: 0.0716\n",
      "Epoch 44: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 141ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "(280, 1)\n",
      "Test RMSE: 497.139\n",
      "Test MAE: 297.643\n",
      "Test R2 Score:  0.7146922327935914\n",
      "MAPE 0.7815068375148831\n",
      "Test MBE 197.00339033497963\n",
      "nRMSE 0.9500050519951583\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "(69, 1)\n",
      "Test RMSE: 264.876\n",
      "Test MAE: 170.215\n",
      "Test R2 Score:  0.10674379106995568\n",
      "MAPE 1.9750164998249322\n",
      "Test MBE 118.60806558997352\n",
      "nRMSE 3.14738266588095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 290ms/step - loss: 0.0440 - mae: 0.1429 - val_loss: 0.0276 - val_mae: 0.1306\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0301 - mae: 0.1301 - val_loss: 0.0241 - val_mae: 0.0865\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0263 - mae: 0.0860 - val_loss: 0.0220 - val_mae: 0.0946\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0333 - mae: 0.1073 - val_loss: 0.0202 - val_mae: 0.0876\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0248 - mae: 0.1080 - val_loss: 0.0188 - val_mae: 0.0800\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0236 - mae: 0.0871 - val_loss: 0.0187 - val_mae: 0.0788\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0227 - mae: 0.1010 - val_loss: 0.0165 - val_mae: 0.0791\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0222 - mae: 0.0890 - val_loss: 0.0179 - val_mae: 0.0764\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0183 - mae: 0.0831 - val_loss: 0.0157 - val_mae: 0.0776\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0188 - mae: 0.0869 - val_loss: 0.0170 - val_mae: 0.0707\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0140 - mae: 0.0697 - val_loss: 0.0153 - val_mae: 0.0832\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0195 - mae: 0.0865 - val_loss: 0.0126 - val_mae: 0.0659\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0208 - mae: 0.0905 - val_loss: 0.0221 - val_mae: 0.0742\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0260 - mae: 0.0862 - val_loss: 0.0150 - val_mae: 0.0764\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0144 - mae: 0.0794 - val_loss: 0.0143 - val_mae: 0.0702\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0161 - mae: 0.0753 - val_loss: 0.0118 - val_mae: 0.0666\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0142 - mae: 0.0746 - val_loss: 0.0138 - val_mae: 0.0645\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 155ms/step - loss: 0.0110 - mae: 0.0601 - val_loss: 0.0108 - val_mae: 0.0638\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0156 - mae: 0.0756 - val_loss: 0.0103 - val_mae: 0.0625\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0110 - mae: 0.0597 - val_loss: 0.0131 - val_mae: 0.0649\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0111 - mae: 0.0598 - val_loss: 0.0127 - val_mae: 0.0670\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0084 - mae: 0.0543 - val_loss: 0.0112 - val_mae: 0.0640\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0086 - mae: 0.0556 - val_loss: 0.0137 - val_mae: 0.0621\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - loss: 0.0127 - mae: 0.0596 - val_loss: 0.0124 - val_mae: 0.0691\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0126 - mae: 0.0679 - val_loss: 0.0115 - val_mae: 0.0642\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0080 - mae: 0.0542 - val_loss: 0.0091 - val_mae: 0.0599\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0076 - mae: 0.0522 - val_loss: 0.0091 - val_mae: 0.0589\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0118 - mae: 0.0645 - val_loss: 0.0196 - val_mae: 0.0733\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0119 - mae: 0.0558 - val_loss: 0.0190 - val_mae: 0.0776\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0122 - mae: 0.0708 - val_loss: 0.0150 - val_mae: 0.0713\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0097 - mae: 0.0548 - val_loss: 0.0104 - val_mae: 0.0671\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0101 - mae: 0.0649 - val_loss: 0.0129 - val_mae: 0.0669\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0090 - mae: 0.0575 - val_loss: 0.0108 - val_mae: 0.0622\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0083 - mae: 0.0511 - val_loss: 0.0122 - val_mae: 0.0673\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0068 - mae: 0.0535 - val_loss: 0.0133 - val_mae: 0.0659\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0071 - mae: 0.0447 - val_loss: 0.0135 - val_mae: 0.0645\n",
      "Epoch 36: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "(280, 1)\n",
      "Test RMSE: 497.139\n",
      "Test MAE: 297.643\n",
      "Test R2 Score:  0.7146922327935914\n",
      "MAPE 0.7815068375148831\n",
      "Test MBE 197.00339033497963\n",
      "nRMSE 0.9500050519951583\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "(69, 1)\n",
      "Test RMSE: 264.876\n",
      "Test MAE: 170.215\n",
      "Test R2 Score:  0.10674379106995568\n",
      "MAPE 1.9750164998249322\n",
      "Test MBE 118.60806558997352\n",
      "nRMSE 3.14738266588095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 263ms/step - loss: 0.0561 - mae: 0.1629 - val_loss: 0.0388 - val_mae: 0.1041\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0349 - mae: 0.1222 - val_loss: 0.0227 - val_mae: 0.1046\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0260 - mae: 0.1033 - val_loss: 0.0226 - val_mae: 0.0889\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0246 - mae: 0.0895 - val_loss: 0.0194 - val_mae: 0.0864\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0253 - mae: 0.1033 - val_loss: 0.0197 - val_mae: 0.0854\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0213 - mae: 0.0914 - val_loss: 0.0187 - val_mae: 0.0933\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0223 - mae: 0.1037 - val_loss: 0.0235 - val_mae: 0.0841\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0245 - mae: 0.0872 - val_loss: 0.0185 - val_mae: 0.0894\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0243 - mae: 0.1056 - val_loss: 0.0193 - val_mae: 0.0801\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0176 - mae: 0.0751 - val_loss: 0.0166 - val_mae: 0.0783\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0211 - mae: 0.0925 - val_loss: 0.0181 - val_mae: 0.0771\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0194 - mae: 0.0742 - val_loss: 0.0146 - val_mae: 0.0789\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0152 - mae: 0.0810 - val_loss: 0.0142 - val_mae: 0.0747\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - loss: 0.0159 - mae: 0.0755 - val_loss: 0.0130 - val_mae: 0.0699\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0144 - mae: 0.0684 - val_loss: 0.0134 - val_mae: 0.0695\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0133 - mae: 0.0631 - val_loss: 0.0109 - val_mae: 0.0638\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0144 - mae: 0.0650 - val_loss: 0.0119 - val_mae: 0.0636\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0146 - mae: 0.0706 - val_loss: 0.0170 - val_mae: 0.0671\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0167 - mae: 0.0746 - val_loss: 0.0113 - val_mae: 0.0666\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0099 - mae: 0.0564 - val_loss: 0.0098 - val_mae: 0.0605\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0141 - mae: 0.0729 - val_loss: 0.0171 - val_mae: 0.0725\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0148 - mae: 0.0697 - val_loss: 0.0135 - val_mae: 0.0726\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0101 - mae: 0.0651 - val_loss: 0.0130 - val_mae: 0.0627\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0112 - mae: 0.0606 - val_loss: 0.0110 - val_mae: 0.0690\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0087 - mae: 0.0599 - val_loss: 0.0122 - val_mae: 0.0647\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0078 - mae: 0.0516 - val_loss: 0.0100 - val_mae: 0.0625\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0091 - mae: 0.0558 - val_loss: 0.0142 - val_mae: 0.0667\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0115 - mae: 0.0600 - val_loss: 0.0105 - val_mae: 0.0660\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0099 - mae: 0.0567 - val_loss: 0.0114 - val_mae: 0.0692\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0077 - mae: 0.0548 - val_loss: 0.0117 - val_mae: 0.0610\n",
      "Epoch 30: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 141ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "(280, 1)\n",
      "Test RMSE: 497.139\n",
      "Test MAE: 297.643\n",
      "Test R2 Score:  0.7146922327935914\n",
      "MAPE 0.7815068375148831\n",
      "Test MBE 197.00339033497963\n",
      "nRMSE 0.9500050519951583\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "(69, 1)\n",
      "Test RMSE: 264.876\n",
      "Test MAE: 170.215\n",
      "Test R2 Score:  0.10674379106995568\n",
      "MAPE 1.9750164998249322\n",
      "Test MBE 118.60806558997352\n",
      "nRMSE 3.14738266588095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 262ms/step - loss: 0.0546 - mae: 0.1579 - val_loss: 0.0298 - val_mae: 0.1052\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0237 - mae: 0.1077 - val_loss: 0.0206 - val_mae: 0.0877\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0220 - mae: 0.0905 - val_loss: 0.0200 - val_mae: 0.0827\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0274 - mae: 0.1066 - val_loss: 0.0211 - val_mae: 0.0801\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0252 - mae: 0.0957 - val_loss: 0.0187 - val_mae: 0.0795\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0191 - mae: 0.0880 - val_loss: 0.0173 - val_mae: 0.0725\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0195 - mae: 0.0845 - val_loss: 0.0191 - val_mae: 0.0717\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0186 - mae: 0.0824 - val_loss: 0.0161 - val_mae: 0.0661\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0185 - mae: 0.0851 - val_loss: 0.0158 - val_mae: 0.0645\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0172 - mae: 0.0725 - val_loss: 0.0163 - val_mae: 0.0692\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0152 - mae: 0.0698 - val_loss: 0.0169 - val_mae: 0.0667\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0127 - mae: 0.0687 - val_loss: 0.0158 - val_mae: 0.0695\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0144 - mae: 0.0712 - val_loss: 0.0191 - val_mae: 0.0720\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0160 - mae: 0.0725 - val_loss: 0.0159 - val_mae: 0.0662\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0148 - mae: 0.0696 - val_loss: 0.0146 - val_mae: 0.0683\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0099 - mae: 0.0556 - val_loss: 0.0147 - val_mae: 0.0709\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0163 - mae: 0.0734 - val_loss: 0.0200 - val_mae: 0.0720\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0128 - mae: 0.0665 - val_loss: 0.0120 - val_mae: 0.0679\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0074 - mae: 0.0504 - val_loss: 0.0139 - val_mae: 0.0643\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0110 - mae: 0.0585 - val_loss: 0.0198 - val_mae: 0.0682\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0134 - mae: 0.0665 - val_loss: 0.0117 - val_mae: 0.0677\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0082 - mae: 0.0502 - val_loss: 0.0129 - val_mae: 0.0626\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0103 - mae: 0.0557 - val_loss: 0.0161 - val_mae: 0.0667\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0142 - mae: 0.0644 - val_loss: 0.0107 - val_mae: 0.0680\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0131 - mae: 0.0676 - val_loss: 0.0129 - val_mae: 0.0647\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0093 - mae: 0.0600 - val_loss: 0.0135 - val_mae: 0.0613\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0083 - mae: 0.0498 - val_loss: 0.0107 - val_mae: 0.0626\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0088 - mae: 0.0545 - val_loss: 0.0189 - val_mae: 0.0697\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0098 - mae: 0.0569 - val_loss: 0.0140 - val_mae: 0.0626\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0082 - mae: 0.0513 - val_loss: 0.0107 - val_mae: 0.0622\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0093 - mae: 0.0557 - val_loss: 0.0160 - val_mae: 0.0664\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0101 - mae: 0.0563 - val_loss: 0.0156 - val_mae: 0.0620\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0078 - mae: 0.0458 - val_loss: 0.0124 - val_mae: 0.0655\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0075 - mae: 0.0513 - val_loss: 0.0145 - val_mae: 0.0640\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0076 - mae: 0.0514 - val_loss: 0.0145 - val_mae: 0.0604\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0072 - mae: 0.0463 - val_loss: 0.0105 - val_mae: 0.0579\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0084 - mae: 0.0491 - val_loss: 0.0156 - val_mae: 0.0604\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0084 - mae: 0.0493 - val_loss: 0.0131 - val_mae: 0.0611\n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0070 - mae: 0.0494 - val_loss: 0.0097 - val_mae: 0.0614\n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0070 - mae: 0.0477 - val_loss: 0.0160 - val_mae: 0.0608\n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0063 - mae: 0.0432 - val_loss: 0.0117 - val_mae: 0.0595\n",
      "Epoch 42/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0075 - mae: 0.0471 - val_loss: 0.0116 - val_mae: 0.0564\n",
      "Epoch 43/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0056 - mae: 0.0407 - val_loss: 0.0156 - val_mae: 0.0622\n",
      "Epoch 44/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0064 - mae: 0.0442 - val_loss: 0.0111 - val_mae: 0.0613\n",
      "Epoch 45/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0073 - mae: 0.0482 - val_loss: 0.0123 - val_mae: 0.0578\n",
      "Epoch 46/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0066 - mae: 0.0468 - val_loss: 0.0139 - val_mae: 0.0608\n",
      "Epoch 47/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0063 - mae: 0.0453 - val_loss: 0.0122 - val_mae: 0.0571\n",
      "Epoch 48/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0081 - mae: 0.0486 - val_loss: 0.0099 - val_mae: 0.0517\n",
      "Epoch 49/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0058 - mae: 0.0424 - val_loss: 0.0178 - val_mae: 0.0616\n",
      "Epoch 49: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 211ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "(280, 1)\n",
      "Test RMSE: 497.139\n",
      "Test MAE: 297.643\n",
      "Test R2 Score:  0.7146922327935914\n",
      "MAPE 0.7815068375148831\n",
      "Test MBE 197.00339033497963\n",
      "nRMSE 0.9500050519951583\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "(69, 1)\n",
      "Test RMSE: 264.876\n",
      "Test MAE: 170.215\n",
      "Test R2 Score:  0.10674379106995568\n",
      "MAPE 1.9750164998249322\n",
      "Test MBE 118.60806558997352\n",
      "nRMSE 3.14738266588095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_19 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 344ms/step - loss: 0.0528 - mae: 0.1582 - val_loss: 0.0368 - val_mae: 0.1072\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0363 - mae: 0.1294 - val_loss: 0.0228 - val_mae: 0.1000\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0265 - mae: 0.1022 - val_loss: 0.0196 - val_mae: 0.0860\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0227 - mae: 0.0958 - val_loss: 0.0184 - val_mae: 0.0824\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0221 - mae: 0.0909 - val_loss: 0.0179 - val_mae: 0.0794\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0260 - mae: 0.1093 - val_loss: 0.0156 - val_mae: 0.0732\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0201 - mae: 0.0825 - val_loss: 0.0145 - val_mae: 0.0790\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0226 - mae: 0.0993 - val_loss: 0.0219 - val_mae: 0.0835\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0270 - mae: 0.0956 - val_loss: 0.0138 - val_mae: 0.0795\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0187 - mae: 0.0897 - val_loss: 0.0168 - val_mae: 0.0696\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0188 - mae: 0.0782 - val_loss: 0.0123 - val_mae: 0.0671\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0174 - mae: 0.0794 - val_loss: 0.0121 - val_mae: 0.0679\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0131 - mae: 0.0701 - val_loss: 0.0131 - val_mae: 0.0612\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0139 - mae: 0.0655 - val_loss: 0.0096 - val_mae: 0.0587\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0136 - mae: 0.0662 - val_loss: 0.0105 - val_mae: 0.0604\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0087 - mae: 0.0574 - val_loss: 0.0152 - val_mae: 0.0654\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0132 - mae: 0.0611 - val_loss: 0.0110 - val_mae: 0.0613\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 0.0116 - mae: 0.0599 - val_loss: 0.0105 - val_mae: 0.0657\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0094 - mae: 0.0618 - val_loss: 0.0115 - val_mae: 0.0598\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0082 - mae: 0.0468 - val_loss: 0.0097 - val_mae: 0.0538\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0106 - mae: 0.0609 - val_loss: 0.0110 - val_mae: 0.0587\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0070 - mae: 0.0463 - val_loss: 0.0095 - val_mae: 0.0629\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0113 - mae: 0.0633 - val_loss: 0.0140 - val_mae: 0.0620\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0078 - mae: 0.0469 - val_loss: 0.0092 - val_mae: 0.0569\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0063 - mae: 0.0454 - val_loss: 0.0113 - val_mae: 0.0605\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0073 - mae: 0.0486 - val_loss: 0.0111 - val_mae: 0.0594\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0077 - mae: 0.0514 - val_loss: 0.0083 - val_mae: 0.0537\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0082 - mae: 0.0516 - val_loss: 0.0114 - val_mae: 0.0584\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0084 - mae: 0.0471 - val_loss: 0.0093 - val_mae: 0.0623\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0069 - mae: 0.0546 - val_loss: 0.0122 - val_mae: 0.0606\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0087 - mae: 0.0494 - val_loss: 0.0116 - val_mae: 0.0583\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0069 - mae: 0.0452 - val_loss: 0.0106 - val_mae: 0.0549\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0079 - mae: 0.0492 - val_loss: 0.0092 - val_mae: 0.0520\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - loss: 0.0084 - mae: 0.0506 - val_loss: 0.0135 - val_mae: 0.0628\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0077 - mae: 0.0528 - val_loss: 0.0109 - val_mae: 0.0600\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0076 - mae: 0.0517 - val_loss: 0.0104 - val_mae: 0.0559\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0065 - mae: 0.0431 - val_loss: 0.0119 - val_mae: 0.0598\n",
      "Epoch 37: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 362ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "(280, 1)\n",
      "Test RMSE: 497.139\n",
      "Test MAE: 297.643\n",
      "Test R2 Score:  0.7146922327935914\n",
      "MAPE 0.7815068375148831\n",
      "Test MBE 197.00339033497963\n",
      "nRMSE 0.9500050519951583\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "(69, 1)\n",
      "Test RMSE: 264.876\n",
      "Test MAE: 170.215\n",
      "Test R2 Score:  0.10674379106995568\n",
      "MAPE 1.9750164998249322\n",
      "Test MBE 118.60806558997352\n",
      "nRMSE 3.14738266588095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_21 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 520ms/step - loss: 0.0490 - mae: 0.1514 - val_loss: 0.0300 - val_mae: 0.1067\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0365 - mae: 0.1398 - val_loss: 0.0235 - val_mae: 0.0854\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0323 - mae: 0.1112 - val_loss: 0.0195 - val_mae: 0.0807\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0274 - mae: 0.1035 - val_loss: 0.0237 - val_mae: 0.0817\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0265 - mae: 0.0845 - val_loss: 0.0225 - val_mae: 0.0843\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0229 - mae: 0.1035 - val_loss: 0.0182 - val_mae: 0.0831\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0236 - mae: 0.0961 - val_loss: 0.0183 - val_mae: 0.0763\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0245 - mae: 0.0948 - val_loss: 0.0164 - val_mae: 0.0767\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0173 - mae: 0.0811 - val_loss: 0.0187 - val_mae: 0.0764\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0177 - mae: 0.0841 - val_loss: 0.0157 - val_mae: 0.0730\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0181 - mae: 0.0824 - val_loss: 0.0150 - val_mae: 0.0699\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0135 - mae: 0.0690 - val_loss: 0.0129 - val_mae: 0.0720\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0112 - mae: 0.0666 - val_loss: 0.0132 - val_mae: 0.0679\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0103 - mae: 0.0611 - val_loss: 0.0147 - val_mae: 0.0677\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0083 - mae: 0.0551 - val_loss: 0.0131 - val_mae: 0.0655\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0126 - mae: 0.0683 - val_loss: 0.0233 - val_mae: 0.0772\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0098 - mae: 0.0538 - val_loss: 0.0153 - val_mae: 0.0719\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0127 - mae: 0.0683 - val_loss: 0.0148 - val_mae: 0.0717\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0110 - mae: 0.0692 - val_loss: 0.0141 - val_mae: 0.0692\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0086 - mae: 0.0504 - val_loss: 0.0132 - val_mae: 0.0670\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0096 - mae: 0.0574 - val_loss: 0.0154 - val_mae: 0.0672\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0098 - mae: 0.0556 - val_loss: 0.0142 - val_mae: 0.0649\n",
      "Epoch 22: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 165ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "(280, 1)\n",
      "Test RMSE: 497.139\n",
      "Test MAE: 297.643\n",
      "Test R2 Score:  0.7146922327935914\n",
      "MAPE 0.7815068375148831\n",
      "Test MBE 197.00339033497963\n",
      "nRMSE 0.9500050519951583\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "(69, 1)\n",
      "Test RMSE: 264.876\n",
      "Test MAE: 170.215\n",
      "Test R2 Score:  0.10674379106995568\n",
      "MAPE 1.9750164998249322\n",
      "Test MBE 118.60806558997352\n",
      "nRMSE 3.14738266588095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_22 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_23 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 283ms/step - loss: 0.0536 - mae: 0.1510 - val_loss: 0.0281 - val_mae: 0.1102\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0308 - mae: 0.1269 - val_loss: 0.0240 - val_mae: 0.0894\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0216 - mae: 0.0872 - val_loss: 0.0213 - val_mae: 0.0845\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0223 - mae: 0.0892 - val_loss: 0.0206 - val_mae: 0.0917\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0254 - mae: 0.1128 - val_loss: 0.0198 - val_mae: 0.0859\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0192 - mae: 0.0887 - val_loss: 0.0193 - val_mae: 0.0795\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 0.0203 - mae: 0.0864 - val_loss: 0.0171 - val_mae: 0.0750\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0220 - mae: 0.0906 - val_loss: 0.0159 - val_mae: 0.0763\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0193 - mae: 0.0877 - val_loss: 0.0154 - val_mae: 0.0690\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0158 - mae: 0.0696 - val_loss: 0.0135 - val_mae: 0.0684\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0186 - mae: 0.0877 - val_loss: 0.0172 - val_mae: 0.0717\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0181 - mae: 0.0770 - val_loss: 0.0140 - val_mae: 0.0656\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0152 - mae: 0.0747 - val_loss: 0.0159 - val_mae: 0.0706\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0235 - mae: 0.0868 - val_loss: 0.0170 - val_mae: 0.0705\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0164 - mae: 0.0669 - val_loss: 0.0166 - val_mae: 0.0796\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0148 - mae: 0.0824 - val_loss: 0.0162 - val_mae: 0.0710\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0175 - mae: 0.0700 - val_loss: 0.0137 - val_mae: 0.0686\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0117 - mae: 0.0623 - val_loss: 0.0135 - val_mae: 0.0708\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0094 - mae: 0.0600 - val_loss: 0.0124 - val_mae: 0.0657\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0118 - mae: 0.0631 - val_loss: 0.0127 - val_mae: 0.0633\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0126 - mae: 0.0591 - val_loss: 0.0135 - val_mae: 0.0716\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0121 - mae: 0.0712 - val_loss: 0.0130 - val_mae: 0.0676\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.0111 - mae: 0.0588 - val_loss: 0.0120 - val_mae: 0.0686\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0097 - mae: 0.0595 - val_loss: 0.0129 - val_mae: 0.0658\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0087 - mae: 0.0511 - val_loss: 0.0130 - val_mae: 0.0658\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0105 - mae: 0.0566 - val_loss: 0.0125 - val_mae: 0.0672\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0084 - mae: 0.0519 - val_loss: 0.0129 - val_mae: 0.0666\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0064 - mae: 0.0458 - val_loss: 0.0130 - val_mae: 0.0667\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0087 - mae: 0.0486 - val_loss: 0.0126 - val_mae: 0.0671\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0105 - mae: 0.0638 - val_loss: 0.0167 - val_mae: 0.0683\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - loss: 0.0148 - mae: 0.0668 - val_loss: 0.0120 - val_mae: 0.0681\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0089 - mae: 0.0552 - val_loss: 0.0124 - val_mae: 0.0664\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0064 - mae: 0.0480 - val_loss: 0.0115 - val_mae: 0.0637\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0069 - mae: 0.0451 - val_loss: 0.0119 - val_mae: 0.0645\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0086 - mae: 0.0542 - val_loss: 0.0146 - val_mae: 0.0655\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0063 - mae: 0.0405 - val_loss: 0.0129 - val_mae: 0.0688\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0081 - mae: 0.0514 - val_loss: 0.0131 - val_mae: 0.0681\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0056 - mae: 0.0480 - val_loss: 0.0121 - val_mae: 0.0634\n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0059 - mae: 0.0445 - val_loss: 0.0122 - val_mae: 0.0611\n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0068 - mae: 0.0468 - val_loss: 0.0114 - val_mae: 0.0613\n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 433ms/step - loss: 0.0065 - mae: 0.0441 - val_loss: 0.0122 - val_mae: 0.0619\n",
      "Epoch 42/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 0.0071 - mae: 0.0464 - val_loss: 0.0155 - val_mae: 0.0592\n",
      "Epoch 43/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0061 - mae: 0.0443 - val_loss: 0.0116 - val_mae: 0.0601\n",
      "Epoch 44/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0058 - mae: 0.0431 - val_loss: 0.0119 - val_mae: 0.0596\n",
      "Epoch 45/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 293ms/step - loss: 0.0060 - mae: 0.0460 - val_loss: 0.0127 - val_mae: 0.0590\n",
      "Epoch 46/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0048 - mae: 0.0401 - val_loss: 0.0113 - val_mae: 0.0601\n",
      "Epoch 47/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0061 - mae: 0.0471 - val_loss: 0.0141 - val_mae: 0.0659\n",
      "Epoch 48/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0073 - mae: 0.0509 - val_loss: 0.0133 - val_mae: 0.0598\n",
      "Epoch 49/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 476ms/step - loss: 0.0049 - mae: 0.0391 - val_loss: 0.0108 - val_mae: 0.0555\n",
      "Epoch 50/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0064 - mae: 0.0459 - val_loss: 0.0125 - val_mae: 0.0565\n",
      "Epoch 51/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0056 - mae: 0.0474 - val_loss: 0.0183 - val_mae: 0.0633\n",
      "Epoch 52/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0056 - mae: 0.0391 - val_loss: 0.0127 - val_mae: 0.0631\n",
      "Epoch 53/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0066 - mae: 0.0501 - val_loss: 0.0145 - val_mae: 0.0619\n",
      "Epoch 54/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0059 - mae: 0.0409 - val_loss: 0.0108 - val_mae: 0.0594\n",
      "Epoch 55/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0057 - mae: 0.0432 - val_loss: 0.0138 - val_mae: 0.0610\n",
      "Epoch 56/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0057 - mae: 0.0429 - val_loss: 0.0136 - val_mae: 0.0601\n",
      "Epoch 57/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0054 - mae: 0.0411 - val_loss: 0.0123 - val_mae: 0.0598\n",
      "Epoch 58/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0083 - mae: 0.0462 - val_loss: 0.0147 - val_mae: 0.0631\n",
      "Epoch 59/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0063 - mae: 0.0505 - val_loss: 0.0205 - val_mae: 0.0718\n",
      "Epoch 59: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "(280, 1)\n",
      "Test RMSE: 497.139\n",
      "Test MAE: 297.643\n",
      "Test R2 Score:  0.7146922327935914\n",
      "MAPE 0.7815068375148831\n",
      "Test MBE 197.00339033497963\n",
      "nRMSE 0.9500050519951583\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "(69, 1)\n",
      "Test RMSE: 264.876\n",
      "Test MAE: 170.215\n",
      "Test R2 Score:  0.10674379106995568\n",
      "MAPE 1.9750164998249322\n",
      "Test MBE 118.60806558997352\n",
      "nRMSE 3.14738266588095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_24 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_25 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 515ms/step - loss: 0.0389 - mae: 0.1308 - val_loss: 0.0261 - val_mae: 0.1135\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0253 - mae: 0.1114 - val_loss: 0.0226 - val_mae: 0.0908\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0285 - mae: 0.1006 - val_loss: 0.0245 - val_mae: 0.0904\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0331 - mae: 0.1190 - val_loss: 0.0229 - val_mae: 0.0930\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0304 - mae: 0.0988 - val_loss: 0.0219 - val_mae: 0.0886\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0257 - mae: 0.1065 - val_loss: 0.0188 - val_mae: 0.0818\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0217 - mae: 0.0853 - val_loss: 0.0187 - val_mae: 0.0803\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0224 - mae: 0.0917 - val_loss: 0.0170 - val_mae: 0.0794\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0176 - mae: 0.0796 - val_loss: 0.0160 - val_mae: 0.0789\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0155 - mae: 0.0748 - val_loss: 0.0146 - val_mae: 0.0713\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0142 - mae: 0.0707 - val_loss: 0.0145 - val_mae: 0.0689\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0143 - mae: 0.0670 - val_loss: 0.0134 - val_mae: 0.0687\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0169 - mae: 0.0752 - val_loss: 0.0129 - val_mae: 0.0679\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0123 - mae: 0.0631 - val_loss: 0.0117 - val_mae: 0.0642\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0122 - mae: 0.0621 - val_loss: 0.0111 - val_mae: 0.0649\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0133 - mae: 0.0692 - val_loss: 0.0109 - val_mae: 0.0617\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0109 - mae: 0.0575 - val_loss: 0.0118 - val_mae: 0.0624\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0111 - mae: 0.0594 - val_loss: 0.0132 - val_mae: 0.0633\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0123 - mae: 0.0615 - val_loss: 0.0153 - val_mae: 0.0676\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0109 - mae: 0.0564 - val_loss: 0.0166 - val_mae: 0.0893\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0125 - mae: 0.0744 - val_loss: 0.0147 - val_mae: 0.0683\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0146 - mae: 0.0674 - val_loss: 0.0134 - val_mae: 0.0720\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0116 - mae: 0.0602 - val_loss: 0.0134 - val_mae: 0.0711\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0098 - mae: 0.0567 - val_loss: 0.0129 - val_mae: 0.0701\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0102 - mae: 0.0579 - val_loss: 0.0124 - val_mae: 0.0628\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0091 - mae: 0.0519 - val_loss: 0.0113 - val_mae: 0.0720\n",
      "Epoch 26: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "(280, 1)\n",
      "Test RMSE: 497.139\n",
      "Test MAE: 297.643\n",
      "Test R2 Score:  0.7146922327935914\n",
      "MAPE 0.7815068375148831\n",
      "Test MBE 197.00339033497963\n",
      "nRMSE 0.9500050519951583\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "(69, 1)\n",
      "Test RMSE: 264.876\n",
      "Test MAE: 170.215\n",
      "Test R2 Score:  0.10674379106995568\n",
      "MAPE 1.9750164998249322\n",
      "Test MBE 118.60806558997352\n",
      "nRMSE 3.14738266588095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_26 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_27 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 292ms/step - loss: 0.0534 - mae: 0.1613 - val_loss: 0.0353 - val_mae: 0.1008\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0309 - mae: 0.1159 - val_loss: 0.0241 - val_mae: 0.0863\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0334 - mae: 0.1111 - val_loss: 0.0217 - val_mae: 0.0941\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0262 - mae: 0.1068 - val_loss: 0.0284 - val_mae: 0.0899\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0257 - mae: 0.0867 - val_loss: 0.0214 - val_mae: 0.1008\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0216 - mae: 0.1026 - val_loss: 0.0217 - val_mae: 0.0826\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0236 - mae: 0.0939 - val_loss: 0.0189 - val_mae: 0.0865\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0215 - mae: 0.0940 - val_loss: 0.0193 - val_mae: 0.0769\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0217 - mae: 0.0809 - val_loss: 0.0168 - val_mae: 0.0815\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0217 - mae: 0.0952 - val_loss: 0.0168 - val_mae: 0.0725\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0192 - mae: 0.0816 - val_loss: 0.0150 - val_mae: 0.0735\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0117 - mae: 0.0630 - val_loss: 0.0158 - val_mae: 0.0711\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0156 - mae: 0.0728 - val_loss: 0.0133 - val_mae: 0.0687\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0122 - mae: 0.0622 - val_loss: 0.0133 - val_mae: 0.0629\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0118 - mae: 0.0631 - val_loss: 0.0116 - val_mae: 0.0605\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0135 - mae: 0.0691 - val_loss: 0.0121 - val_mae: 0.0638\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0118 - mae: 0.0635 - val_loss: 0.0161 - val_mae: 0.0695\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0129 - mae: 0.0682 - val_loss: 0.0171 - val_mae: 0.0699\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0134 - mae: 0.0602 - val_loss: 0.0126 - val_mae: 0.0682\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0132 - mae: 0.0664 - val_loss: 0.0133 - val_mae: 0.0671\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0116 - mae: 0.0641 - val_loss: 0.0124 - val_mae: 0.0660\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0117 - mae: 0.0608 - val_loss: 0.0122 - val_mae: 0.0618\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0067 - mae: 0.0471 - val_loss: 0.0114 - val_mae: 0.0622\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0087 - mae: 0.0537 - val_loss: 0.0116 - val_mae: 0.0645\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0067 - mae: 0.0495 - val_loss: 0.0112 - val_mae: 0.0614\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0098 - mae: 0.0598 - val_loss: 0.0186 - val_mae: 0.0722\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0093 - mae: 0.0546 - val_loss: 0.0108 - val_mae: 0.0600\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0074 - mae: 0.0504 - val_loss: 0.0107 - val_mae: 0.0602\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0092 - mae: 0.0595 - val_loss: 0.0212 - val_mae: 0.0745\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0092 - mae: 0.0483 - val_loss: 0.0143 - val_mae: 0.0715\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0108 - mae: 0.0668 - val_loss: 0.0167 - val_mae: 0.0694\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0085 - mae: 0.0507 - val_loss: 0.0114 - val_mae: 0.0678\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0060 - mae: 0.0467 - val_loss: 0.0126 - val_mae: 0.0607\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0068 - mae: 0.0459 - val_loss: 0.0091 - val_mae: 0.0568\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0059 - mae: 0.0417 - val_loss: 0.0113 - val_mae: 0.0645\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0073 - mae: 0.0514 - val_loss: 0.0138 - val_mae: 0.0663\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0090 - mae: 0.0547 - val_loss: 0.0109 - val_mae: 0.0605\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - loss: 0.0083 - mae: 0.0515 - val_loss: 0.0115 - val_mae: 0.0642\n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0103 - mae: 0.0596 - val_loss: 0.0131 - val_mae: 0.0626\n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0057 - mae: 0.0438 - val_loss: 0.0113 - val_mae: 0.0588\n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0075 - mae: 0.0472 - val_loss: 0.0114 - val_mae: 0.0592\n",
      "Epoch 42/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0052 - mae: 0.0393 - val_loss: 0.0115 - val_mae: 0.0624\n",
      "Epoch 43/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0056 - mae: 0.0480 - val_loss: 0.0139 - val_mae: 0.0653\n",
      "Epoch 44/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0044 - mae: 0.0375 - val_loss: 0.0124 - val_mae: 0.0642\n",
      "Epoch 44: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 211ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "(280, 1)\n",
      "Test RMSE: 497.139\n",
      "Test MAE: 297.643\n",
      "Test R2 Score:  0.7146922327935914\n",
      "MAPE 0.7815068375148831\n",
      "Test MBE 197.00339033497963\n",
      "nRMSE 0.9500050519951583\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "(69, 1)\n",
      "Test RMSE: 264.876\n",
      "Test MAE: 170.215\n",
      "Test R2 Score:  0.10674379106995568\n",
      "MAPE 1.9750164998249322\n",
      "Test MBE 118.60806558997352\n",
      "nRMSE 3.14738266588095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_14\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_14\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_28 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_29 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 271ms/step - loss: 0.0376 - mae: 0.1355 - val_loss: 0.0305 - val_mae: 0.1269\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0282 - mae: 0.1252 - val_loss: 0.0231 - val_mae: 0.0925\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0271 - mae: 0.0985 - val_loss: 0.0239 - val_mae: 0.0861\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0233 - mae: 0.0885 - val_loss: 0.0216 - val_mae: 0.0976\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0260 - mae: 0.1091 - val_loss: 0.0208 - val_mae: 0.0831\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0249 - mae: 0.1006 - val_loss: 0.0246 - val_mae: 0.0831\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0270 - mae: 0.0942 - val_loss: 0.0195 - val_mae: 0.0921\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0154 - mae: 0.0800 - val_loss: 0.0214 - val_mae: 0.0778\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0206 - mae: 0.0790 - val_loss: 0.0174 - val_mae: 0.0756\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0170 - mae: 0.0775 - val_loss: 0.0173 - val_mae: 0.0752\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0241 - mae: 0.1008 - val_loss: 0.0275 - val_mae: 0.0819\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0172 - mae: 0.0686 - val_loss: 0.0213 - val_mae: 0.0920\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0208 - mae: 0.0948 - val_loss: 0.0229 - val_mae: 0.0803\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0231 - mae: 0.0868 - val_loss: 0.0177 - val_mae: 0.0821\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0133 - mae: 0.0692 - val_loss: 0.0180 - val_mae: 0.0783\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0136 - mae: 0.0711 - val_loss: 0.0162 - val_mae: 0.0773\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0125 - mae: 0.0693 - val_loss: 0.0152 - val_mae: 0.0736\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0136 - mae: 0.0669 - val_loss: 0.0158 - val_mae: 0.0783\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0115 - mae: 0.0635 - val_loss: 0.0152 - val_mae: 0.0711\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0081 - mae: 0.0480 - val_loss: 0.0144 - val_mae: 0.0721\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0104 - mae: 0.0603 - val_loss: 0.0161 - val_mae: 0.0725\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0074 - mae: 0.0526 - val_loss: 0.0148 - val_mae: 0.0687\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0105 - mae: 0.0570 - val_loss: 0.0148 - val_mae: 0.0754\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0100 - mae: 0.0623 - val_loss: 0.0180 - val_mae: 0.0717\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0112 - mae: 0.0629 - val_loss: 0.0150 - val_mae: 0.0709\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0109 - mae: 0.0600 - val_loss: 0.0162 - val_mae: 0.0731\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0079 - mae: 0.0533 - val_loss: 0.0160 - val_mae: 0.0730\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0078 - mae: 0.0511 - val_loss: 0.0157 - val_mae: 0.0739\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0090 - mae: 0.0573 - val_loss: 0.0188 - val_mae: 0.0710\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0106 - mae: 0.0554 - val_loss: 0.0144 - val_mae: 0.0699\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0075 - mae: 0.0489 - val_loss: 0.0154 - val_mae: 0.0728\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0091 - mae: 0.0585 - val_loss: 0.0144 - val_mae: 0.0700\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0098 - mae: 0.0555 - val_loss: 0.0155 - val_mae: 0.0714\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0084 - mae: 0.0516 - val_loss: 0.0132 - val_mae: 0.0651\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0061 - mae: 0.0468 - val_loss: 0.0136 - val_mae: 0.0671\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0083 - mae: 0.0509 - val_loss: 0.0155 - val_mae: 0.0716\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0071 - mae: 0.0456 - val_loss: 0.0178 - val_mae: 0.0726\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0053 - mae: 0.0422 - val_loss: 0.0144 - val_mae: 0.0693\n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0083 - mae: 0.0519 - val_loss: 0.0119 - val_mae: 0.0660\n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0066 - mae: 0.0472 - val_loss: 0.0142 - val_mae: 0.0752\n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0072 - mae: 0.0549 - val_loss: 0.0183 - val_mae: 0.0706\n",
      "Epoch 42/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0080 - mae: 0.0480 - val_loss: 0.0164 - val_mae: 0.0735\n",
      "Epoch 43/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0071 - mae: 0.0531 - val_loss: 0.0172 - val_mae: 0.0723\n",
      "Epoch 44/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0059 - mae: 0.0475 - val_loss: 0.0151 - val_mae: 0.0705\n",
      "Epoch 45/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0056 - mae: 0.0443 - val_loss: 0.0139 - val_mae: 0.0671\n",
      "Epoch 46/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0052 - mae: 0.0427 - val_loss: 0.0142 - val_mae: 0.0678\n",
      "Epoch 47/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0060 - mae: 0.0469 - val_loss: 0.0123 - val_mae: 0.0638\n",
      "Epoch 48/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0064 - mae: 0.0425 - val_loss: 0.0119 - val_mae: 0.0647\n",
      "Epoch 49/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0053 - mae: 0.0455 - val_loss: 0.0155 - val_mae: 0.0672\n",
      "Epoch 49: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 179ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "(280, 1)\n",
      "Test RMSE: 497.139\n",
      "Test MAE: 297.643\n",
      "Test R2 Score:  0.7146922327935914\n",
      "MAPE 0.7815068375148831\n",
      "Test MBE 197.00339033497963\n",
      "nRMSE 0.9500050519951583\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "(69, 1)\n",
      "Test RMSE: 264.876\n",
      "Test MAE: 170.215\n",
      "Test R2 Score:  0.10674379106995568\n",
      "MAPE 1.9750164998249322\n",
      "Test MBE 118.60806558997352\n",
      "nRMSE 3.14738266588095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_15\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_15\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_30 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_31 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 267ms/step - loss: 0.0451 - mae: 0.1447 - val_loss: 0.0262 - val_mae: 0.1125\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0367 - mae: 0.1358 - val_loss: 0.0285 - val_mae: 0.0987\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0279 - mae: 0.1008 - val_loss: 0.0230 - val_mae: 0.0909\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0294 - mae: 0.1014 - val_loss: 0.0212 - val_mae: 0.0935\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0206 - mae: 0.0978 - val_loss: 0.0197 - val_mae: 0.0827\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0205 - mae: 0.0858 - val_loss: 0.0180 - val_mae: 0.0790\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0187 - mae: 0.0822 - val_loss: 0.0182 - val_mae: 0.0776\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0175 - mae: 0.0801 - val_loss: 0.0182 - val_mae: 0.0748\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0187 - mae: 0.0853 - val_loss: 0.0157 - val_mae: 0.0715\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0180 - mae: 0.0772 - val_loss: 0.0135 - val_mae: 0.0671\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0165 - mae: 0.0749 - val_loss: 0.0136 - val_mae: 0.0676\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0120 - mae: 0.0655 - val_loss: 0.0139 - val_mae: 0.0684\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0131 - mae: 0.0687 - val_loss: 0.0152 - val_mae: 0.0704\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0154 - mae: 0.0684 - val_loss: 0.0132 - val_mae: 0.0697\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0123 - mae: 0.0676 - val_loss: 0.0132 - val_mae: 0.0685\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0125 - mae: 0.0661 - val_loss: 0.0136 - val_mae: 0.0694\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0123 - mae: 0.0641 - val_loss: 0.0216 - val_mae: 0.0743\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0188 - mae: 0.0737 - val_loss: 0.0152 - val_mae: 0.0732\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0158 - mae: 0.0732 - val_loss: 0.0160 - val_mae: 0.0703\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0104 - mae: 0.0581 - val_loss: 0.0128 - val_mae: 0.0662\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0078 - mae: 0.0484 - val_loss: 0.0134 - val_mae: 0.0700\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0134 - mae: 0.0725 - val_loss: 0.0158 - val_mae: 0.0705\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0108 - mae: 0.0625 - val_loss: 0.0128 - val_mae: 0.0721\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0093 - mae: 0.0563 - val_loss: 0.0142 - val_mae: 0.0717\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step - loss: 0.0126 - mae: 0.0664 - val_loss: 0.0170 - val_mae: 0.0722\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0083 - mae: 0.0519 - val_loss: 0.0131 - val_mae: 0.0744\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0081 - mae: 0.0579 - val_loss: 0.0139 - val_mae: 0.0641\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0092 - mae: 0.0574 - val_loss: 0.0156 - val_mae: 0.0662\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0107 - mae: 0.0558 - val_loss: 0.0108 - val_mae: 0.0663\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0081 - mae: 0.0592 - val_loss: 0.0179 - val_mae: 0.0712\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0102 - mae: 0.0567 - val_loss: 0.0126 - val_mae: 0.0635\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0082 - mae: 0.0530 - val_loss: 0.0132 - val_mae: 0.0655\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0084 - mae: 0.0556 - val_loss: 0.0165 - val_mae: 0.0688\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0083 - mae: 0.0530 - val_loss: 0.0174 - val_mae: 0.0671\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0079 - mae: 0.0503 - val_loss: 0.0118 - val_mae: 0.0618\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0076 - mae: 0.0521 - val_loss: 0.0187 - val_mae: 0.0659\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0077 - mae: 0.0506 - val_loss: 0.0138 - val_mae: 0.0647\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0116 - mae: 0.0550 - val_loss: 0.0117 - val_mae: 0.0700\n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0107 - mae: 0.0631 - val_loss: 0.0159 - val_mae: 0.0720\n",
      "Epoch 39: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "(280, 1)\n",
      "Test RMSE: 497.139\n",
      "Test MAE: 297.643\n",
      "Test R2 Score:  0.7146922327935914\n",
      "MAPE 0.7815068375148831\n",
      "Test MBE 197.00339033497963\n",
      "nRMSE 0.9500050519951583\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "(69, 1)\n",
      "Test RMSE: 264.876\n",
      "Test MAE: 170.215\n",
      "Test R2 Score:  0.10674379106995568\n",
      "MAPE 1.9750164998249322\n",
      "Test MBE 118.60806558997352\n",
      "nRMSE 3.14738266588095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_16\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_16\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_32 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_33 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 273ms/step - loss: 0.0596 - mae: 0.1560 - val_loss: 0.0329 - val_mae: 0.1061\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0297 - mae: 0.1200 - val_loss: 0.0236 - val_mae: 0.0873\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0263 - mae: 0.0954 - val_loss: 0.0202 - val_mae: 0.0913\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0279 - mae: 0.1123 - val_loss: 0.0260 - val_mae: 0.0846\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0334 - mae: 0.1086 - val_loss: 0.0178 - val_mae: 0.0875\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0191 - mae: 0.0895 - val_loss: 0.0173 - val_mae: 0.0748\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0181 - mae: 0.0782 - val_loss: 0.0158 - val_mae: 0.0727\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0192 - mae: 0.0819 - val_loss: 0.0171 - val_mae: 0.0720\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0143 - mae: 0.0719 - val_loss: 0.0135 - val_mae: 0.0659\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0154 - mae: 0.0683 - val_loss: 0.0112 - val_mae: 0.0617\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0146 - mae: 0.0669 - val_loss: 0.0130 - val_mae: 0.0632\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0133 - mae: 0.0666 - val_loss: 0.0103 - val_mae: 0.0605\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0125 - mae: 0.0630 - val_loss: 0.0095 - val_mae: 0.0613\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0139 - mae: 0.0720 - val_loss: 0.0114 - val_mae: 0.0622\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0120 - mae: 0.0730 - val_loss: 0.0103 - val_mae: 0.0602\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0101 - mae: 0.0569 - val_loss: 0.0093 - val_mae: 0.0562\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0131 - mae: 0.0659 - val_loss: 0.0159 - val_mae: 0.0626\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0133 - mae: 0.0635 - val_loss: 0.0111 - val_mae: 0.0626\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0115 - mae: 0.0588 - val_loss: 0.0109 - val_mae: 0.0626\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0128 - mae: 0.0700 - val_loss: 0.0121 - val_mae: 0.0570\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0098 - mae: 0.0517 - val_loss: 0.0121 - val_mae: 0.0672\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0126 - mae: 0.0677 - val_loss: 0.0129 - val_mae: 0.0597\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0084 - mae: 0.0548 - val_loss: 0.0104 - val_mae: 0.0651\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0084 - mae: 0.0529 - val_loss: 0.0111 - val_mae: 0.0599\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0072 - mae: 0.0480 - val_loss: 0.0100 - val_mae: 0.0584\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0087 - mae: 0.0536 - val_loss: 0.0093 - val_mae: 0.0542\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0085 - mae: 0.0564 - val_loss: 0.0085 - val_mae: 0.0511\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0083 - mae: 0.0490 - val_loss: 0.0085 - val_mae: 0.0541\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0078 - mae: 0.0536 - val_loss: 0.0114 - val_mae: 0.0578\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0061 - mae: 0.0435 - val_loss: 0.0095 - val_mae: 0.0533\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0067 - mae: 0.0459 - val_loss: 0.0086 - val_mae: 0.0542\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0084 - mae: 0.0505 - val_loss: 0.0093 - val_mae: 0.0549\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0072 - mae: 0.0487 - val_loss: 0.0134 - val_mae: 0.0591\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0098 - mae: 0.0540 - val_loss: 0.0110 - val_mae: 0.0640\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0080 - mae: 0.0525 - val_loss: 0.0101 - val_mae: 0.0554\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0086 - mae: 0.0489 - val_loss: 0.0200 - val_mae: 0.0653\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0079 - mae: 0.0485 - val_loss: 0.0099 - val_mae: 0.0593\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0098 - mae: 0.0556 - val_loss: 0.0112 - val_mae: 0.0593\n",
      "Epoch 38: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "(280, 1)\n",
      "Test RMSE: 497.139\n",
      "Test MAE: 297.643\n",
      "Test R2 Score:  0.7146922327935914\n",
      "MAPE 0.7815068375148831\n",
      "Test MBE 197.00339033497963\n",
      "nRMSE 0.9500050519951583\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "(69, 1)\n",
      "Test RMSE: 264.876\n",
      "Test MAE: 170.215\n",
      "Test R2 Score:  0.10674379106995568\n",
      "MAPE 1.9750164998249322\n",
      "Test MBE 118.60806558997352\n",
      "nRMSE 3.14738266588095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_17\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_17\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_34 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_35 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 272ms/step - loss: 0.0425 - mae: 0.1447 - val_loss: 0.0327 - val_mae: 0.1047\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0325 - mae: 0.1338 - val_loss: 0.0267 - val_mae: 0.0897\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0338 - mae: 0.0973 - val_loss: 0.0211 - val_mae: 0.0854\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0283 - mae: 0.1080 - val_loss: 0.0255 - val_mae: 0.0880\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0258 - mae: 0.0898 - val_loss: 0.0248 - val_mae: 0.0924\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0281 - mae: 0.1105 - val_loss: 0.0199 - val_mae: 0.0998\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0233 - mae: 0.1009 - val_loss: 0.0207 - val_mae: 0.0830\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0220 - mae: 0.0832 - val_loss: 0.0186 - val_mae: 0.0861\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0202 - mae: 0.0888 - val_loss: 0.0194 - val_mae: 0.0780\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0188 - mae: 0.0809 - val_loss: 0.0171 - val_mae: 0.0786\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0156 - mae: 0.0757 - val_loss: 0.0156 - val_mae: 0.0743\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0116 - mae: 0.0591 - val_loss: 0.0160 - val_mae: 0.0752\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0159 - mae: 0.0715 - val_loss: 0.0163 - val_mae: 0.0766\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0126 - mae: 0.0630 - val_loss: 0.0152 - val_mae: 0.0732\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0122 - mae: 0.0614 - val_loss: 0.0146 - val_mae: 0.0756\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0115 - mae: 0.0620 - val_loss: 0.0151 - val_mae: 0.0744\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0111 - mae: 0.0619 - val_loss: 0.0159 - val_mae: 0.0825\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0117 - mae: 0.0672 - val_loss: 0.0146 - val_mae: 0.0722\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0114 - mae: 0.0605 - val_loss: 0.0182 - val_mae: 0.0769\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0138 - mae: 0.0672 - val_loss: 0.0191 - val_mae: 0.0854\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0119 - mae: 0.0660 - val_loss: 0.0181 - val_mae: 0.0724\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0119 - mae: 0.0617 - val_loss: 0.0144 - val_mae: 0.0774\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0079 - mae: 0.0565 - val_loss: 0.0150 - val_mae: 0.0741\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0093 - mae: 0.0584 - val_loss: 0.0134 - val_mae: 0.0719\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0081 - mae: 0.0555 - val_loss: 0.0134 - val_mae: 0.0709\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0087 - mae: 0.0526 - val_loss: 0.0142 - val_mae: 0.0709\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0083 - mae: 0.0581 - val_loss: 0.0147 - val_mae: 0.0718\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0086 - mae: 0.0568 - val_loss: 0.0134 - val_mae: 0.0676\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0080 - mae: 0.0538 - val_loss: 0.0180 - val_mae: 0.0738\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0085 - mae: 0.0531 - val_loss: 0.0132 - val_mae: 0.0696\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0072 - mae: 0.0486 - val_loss: 0.0122 - val_mae: 0.0666\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0085 - mae: 0.0519 - val_loss: 0.0143 - val_mae: 0.0672\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0068 - mae: 0.0491 - val_loss: 0.0128 - val_mae: 0.0626\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0061 - mae: 0.0478 - val_loss: 0.0142 - val_mae: 0.0637\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0078 - mae: 0.0473 - val_loss: 0.0132 - val_mae: 0.0649\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0061 - mae: 0.0460 - val_loss: 0.0108 - val_mae: 0.0624\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0087 - mae: 0.0554 - val_loss: 0.0135 - val_mae: 0.0643\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0067 - mae: 0.0514 - val_loss: 0.0131 - val_mae: 0.0657\n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0087 - mae: 0.0492 - val_loss: 0.0137 - val_mae: 0.0723\n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0074 - mae: 0.0542 - val_loss: 0.0127 - val_mae: 0.0675\n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0063 - mae: 0.0482 - val_loss: 0.0143 - val_mae: 0.0674\n",
      "Epoch 42/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0069 - mae: 0.0481 - val_loss: 0.0154 - val_mae: 0.0670\n",
      "Epoch 43/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0056 - mae: 0.0406 - val_loss: 0.0111 - val_mae: 0.0606\n",
      "Epoch 44/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0071 - mae: 0.0429 - val_loss: 0.0121 - val_mae: 0.0686\n",
      "Epoch 45/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0060 - mae: 0.0465 - val_loss: 0.0139 - val_mae: 0.0663\n",
      "Epoch 46/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0048 - mae: 0.0430 - val_loss: 0.0109 - val_mae: 0.0594\n",
      "Epoch 46: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 165ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "(280, 1)\n",
      "Test RMSE: 497.139\n",
      "Test MAE: 297.643\n",
      "Test R2 Score:  0.7146922327935914\n",
      "MAPE 0.7815068375148831\n",
      "Test MBE 197.00339033497963\n",
      "nRMSE 0.9500050519951583\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "(69, 1)\n",
      "Test RMSE: 264.876\n",
      "Test MAE: 170.215\n",
      "Test R2 Score:  0.10674379106995568\n",
      "MAPE 1.9750164998249322\n",
      "Test MBE 118.60806558997352\n",
      "nRMSE 3.14738266588095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_18\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_18\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_36 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_37 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 595ms/step - loss: 0.0387 - mae: 0.1336 - val_loss: 0.0239 - val_mae: 0.1055\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0249 - mae: 0.1159 - val_loss: 0.0197 - val_mae: 0.0859\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0273 - mae: 0.1023 - val_loss: 0.0182 - val_mae: 0.0803\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0212 - mae: 0.0956 - val_loss: 0.0166 - val_mae: 0.0807\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0194 - mae: 0.0886 - val_loss: 0.0147 - val_mae: 0.0725\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0216 - mae: 0.0934 - val_loss: 0.0182 - val_mae: 0.0783\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0168 - mae: 0.0709 - val_loss: 0.0152 - val_mae: 0.0711\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0211 - mae: 0.0860 - val_loss: 0.0168 - val_mae: 0.0725\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0147 - mae: 0.0716 - val_loss: 0.0126 - val_mae: 0.0678\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0143 - mae: 0.0752 - val_loss: 0.0145 - val_mae: 0.0690\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0168 - mae: 0.0739 - val_loss: 0.0122 - val_mae: 0.0600\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0144 - mae: 0.0678 - val_loss: 0.0134 - val_mae: 0.0630\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0158 - mae: 0.0712 - val_loss: 0.0228 - val_mae: 0.0792\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0134 - mae: 0.0593 - val_loss: 0.0141 - val_mae: 0.0810\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0128 - mae: 0.0740 - val_loss: 0.0160 - val_mae: 0.0716\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0127 - mae: 0.0636 - val_loss: 0.0121 - val_mae: 0.0692\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0121 - mae: 0.0672 - val_loss: 0.0123 - val_mae: 0.0671\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0103 - mae: 0.0588 - val_loss: 0.0214 - val_mae: 0.0761\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0115 - mae: 0.0595 - val_loss: 0.0125 - val_mae: 0.0711\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0107 - mae: 0.0631 - val_loss: 0.0138 - val_mae: 0.0663\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0083 - mae: 0.0521 - val_loss: 0.0120 - val_mae: 0.0671\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0103 - mae: 0.0562 - val_loss: 0.0131 - val_mae: 0.0679\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0081 - mae: 0.0533 - val_loss: 0.0168 - val_mae: 0.0701\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0095 - mae: 0.0561 - val_loss: 0.0118 - val_mae: 0.0621\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0091 - mae: 0.0532 - val_loss: 0.0102 - val_mae: 0.0596\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0104 - mae: 0.0602 - val_loss: 0.0124 - val_mae: 0.0655\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0079 - mae: 0.0539 - val_loss: 0.0112 - val_mae: 0.0614\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0074 - mae: 0.0525 - val_loss: 0.0118 - val_mae: 0.0617\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0079 - mae: 0.0496 - val_loss: 0.0126 - val_mae: 0.0637\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0071 - mae: 0.0530 - val_loss: 0.0206 - val_mae: 0.0756\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0092 - mae: 0.0540 - val_loss: 0.0100 - val_mae: 0.0604\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0070 - mae: 0.0495 - val_loss: 0.0135 - val_mae: 0.0624\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0081 - mae: 0.0596 - val_loss: 0.0126 - val_mae: 0.0624\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0059 - mae: 0.0421 - val_loss: 0.0132 - val_mae: 0.0651\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0095 - mae: 0.0576 - val_loss: 0.0166 - val_mae: 0.0719\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0069 - mae: 0.0470 - val_loss: 0.0130 - val_mae: 0.0701\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - loss: 0.0081 - mae: 0.0533 - val_loss: 0.0136 - val_mae: 0.0680\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0066 - mae: 0.0462 - val_loss: 0.0132 - val_mae: 0.0651\n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0054 - mae: 0.0436 - val_loss: 0.0122 - val_mae: 0.0655\n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0058 - mae: 0.0461 - val_loss: 0.0126 - val_mae: 0.0619\n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0048 - mae: 0.0384 - val_loss: 0.0156 - val_mae: 0.0697\n",
      "Epoch 41: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 170ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "(280, 1)\n",
      "Test RMSE: 497.139\n",
      "Test MAE: 297.643\n",
      "Test R2 Score:  0.7146922327935914\n",
      "MAPE 0.7815068375148831\n",
      "Test MBE 197.00339033497963\n",
      "nRMSE 0.9500050519951583\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "(69, 1)\n",
      "Test RMSE: 264.876\n",
      "Test MAE: 170.215\n",
      "Test R2 Score:  0.10674379106995568\n",
      "MAPE 1.9750164998249322\n",
      "Test MBE 118.60806558997352\n",
      "nRMSE 3.14738266588095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_19\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_19\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_38 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_39 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 252ms/step - loss: 0.0446 - mae: 0.1467 - val_loss: 0.0287 - val_mae: 0.1060\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0360 - mae: 0.1323 - val_loss: 0.0243 - val_mae: 0.0933\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0309 - mae: 0.0970 - val_loss: 0.0237 - val_mae: 0.0878\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0355 - mae: 0.1122 - val_loss: 0.0199 - val_mae: 0.0891\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0235 - mae: 0.0982 - val_loss: 0.0184 - val_mae: 0.0817\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0224 - mae: 0.0878 - val_loss: 0.0165 - val_mae: 0.0795\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0225 - mae: 0.0956 - val_loss: 0.0179 - val_mae: 0.0779\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0158 - mae: 0.0780 - val_loss: 0.0153 - val_mae: 0.0835\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0136 - mae: 0.0701 - val_loss: 0.0143 - val_mae: 0.0675\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0172 - mae: 0.0775 - val_loss: 0.0194 - val_mae: 0.0786\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0146 - mae: 0.0674 - val_loss: 0.0174 - val_mae: 0.0759\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0206 - mae: 0.0726 - val_loss: 0.0153 - val_mae: 0.0815\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0151 - mae: 0.0884 - val_loss: 0.0147 - val_mae: 0.0733\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0165 - mae: 0.0704 - val_loss: 0.0130 - val_mae: 0.0683\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0140 - mae: 0.0671 - val_loss: 0.0129 - val_mae: 0.0699\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0153 - mae: 0.0784 - val_loss: 0.0194 - val_mae: 0.0719\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0133 - mae: 0.0580 - val_loss: 0.0153 - val_mae: 0.0734\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0143 - mae: 0.0713 - val_loss: 0.0205 - val_mae: 0.0765\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0139 - mae: 0.0624 - val_loss: 0.0157 - val_mae: 0.0751\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0142 - mae: 0.0758 - val_loss: 0.0161 - val_mae: 0.0670\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0103 - mae: 0.0523 - val_loss: 0.0126 - val_mae: 0.0686\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0107 - mae: 0.0607 - val_loss: 0.0137 - val_mae: 0.0672\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0087 - mae: 0.0554 - val_loss: 0.0131 - val_mae: 0.0675\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0102 - mae: 0.0568 - val_loss: 0.0134 - val_mae: 0.0655\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0085 - mae: 0.0498 - val_loss: 0.0128 - val_mae: 0.0689\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step - loss: 0.0107 - mae: 0.0602 - val_loss: 0.0126 - val_mae: 0.0648\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0098 - mae: 0.0496 - val_loss: 0.0131 - val_mae: 0.0684\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0079 - mae: 0.0542 - val_loss: 0.0168 - val_mae: 0.0674\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0107 - mae: 0.0563 - val_loss: 0.0127 - val_mae: 0.0620\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0072 - mae: 0.0475 - val_loss: 0.0130 - val_mae: 0.0634\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0075 - mae: 0.0458 - val_loss: 0.0155 - val_mae: 0.0678\n",
      "Epoch 31: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 129ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "(280, 1)\n",
      "Test RMSE: 497.139\n",
      "Test MAE: 297.643\n",
      "Test R2 Score:  0.7146922327935914\n",
      "MAPE 0.7815068375148831\n",
      "Test MBE 197.00339033497963\n",
      "nRMSE 0.9500050519951583\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "(69, 1)\n",
      "Test RMSE: 264.876\n",
      "Test MAE: 170.215\n",
      "Test R2 Score:  0.10674379106995568\n",
      "MAPE 1.9750164998249322\n",
      "Test MBE 118.60806558997352\n",
      "nRMSE 3.14738266588095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_20\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_20\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_40 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_41 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 254ms/step - loss: 0.0491 - mae: 0.1470 - val_loss: 0.0308 - val_mae: 0.1379\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0355 - mae: 0.1486 - val_loss: 0.0300 - val_mae: 0.0911\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0326 - mae: 0.0984 - val_loss: 0.0207 - val_mae: 0.0864\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0270 - mae: 0.1042 - val_loss: 0.0210 - val_mae: 0.0953\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0230 - mae: 0.1118 - val_loss: 0.0204 - val_mae: 0.0851\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0252 - mae: 0.0957 - val_loss: 0.0176 - val_mae: 0.0817\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0264 - mae: 0.1030 - val_loss: 0.0196 - val_mae: 0.0818\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0226 - mae: 0.0955 - val_loss: 0.0172 - val_mae: 0.0796\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0218 - mae: 0.0940 - val_loss: 0.0197 - val_mae: 0.0784\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0191 - mae: 0.0828 - val_loss: 0.0163 - val_mae: 0.0737\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0198 - mae: 0.0888 - val_loss: 0.0147 - val_mae: 0.0731\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0149 - mae: 0.0785 - val_loss: 0.0163 - val_mae: 0.0733\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0181 - mae: 0.0748 - val_loss: 0.0142 - val_mae: 0.0720\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0169 - mae: 0.0781 - val_loss: 0.0138 - val_mae: 0.0695\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0140 - mae: 0.0660 - val_loss: 0.0130 - val_mae: 0.0691\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0140 - mae: 0.0710 - val_loss: 0.0135 - val_mae: 0.0643\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0181 - mae: 0.0778 - val_loss: 0.0131 - val_mae: 0.0674\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0123 - mae: 0.0649 - val_loss: 0.0161 - val_mae: 0.0738\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0157 - mae: 0.0692 - val_loss: 0.0137 - val_mae: 0.0713\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0159 - mae: 0.0838 - val_loss: 0.0142 - val_mae: 0.0677\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0130 - mae: 0.0563 - val_loss: 0.0130 - val_mae: 0.0688\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0133 - mae: 0.0759 - val_loss: 0.0137 - val_mae: 0.0731\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0118 - mae: 0.0697 - val_loss: 0.0124 - val_mae: 0.0695\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0080 - mae: 0.0559 - val_loss: 0.0113 - val_mae: 0.0587\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0095 - mae: 0.0544 - val_loss: 0.0117 - val_mae: 0.0615\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0114 - mae: 0.0604 - val_loss: 0.0117 - val_mae: 0.0666\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0096 - mae: 0.0601 - val_loss: 0.0111 - val_mae: 0.0609\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0114 - mae: 0.0586 - val_loss: 0.0121 - val_mae: 0.0691\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0096 - mae: 0.0594 - val_loss: 0.0123 - val_mae: 0.0664\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0080 - mae: 0.0493 - val_loss: 0.0112 - val_mae: 0.0635\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0079 - mae: 0.0493 - val_loss: 0.0108 - val_mae: 0.0651\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0095 - mae: 0.0629 - val_loss: 0.0174 - val_mae: 0.0732\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0136 - mae: 0.0682 - val_loss: 0.0116 - val_mae: 0.0631\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0080 - mae: 0.0498 - val_loss: 0.0114 - val_mae: 0.0644\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0080 - mae: 0.0541 - val_loss: 0.0106 - val_mae: 0.0612\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0097 - mae: 0.0544 - val_loss: 0.0112 - val_mae: 0.0639\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0117 - mae: 0.0647 - val_loss: 0.0121 - val_mae: 0.0644\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0091 - mae: 0.0508 - val_loss: 0.0097 - val_mae: 0.0627\n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0085 - mae: 0.0512 - val_loss: 0.0097 - val_mae: 0.0600\n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0080 - mae: 0.0551 - val_loss: 0.0124 - val_mae: 0.0631\n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0074 - mae: 0.0515 - val_loss: 0.0111 - val_mae: 0.0650\n",
      "Epoch 42/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0080 - mae: 0.0547 - val_loss: 0.0114 - val_mae: 0.0629\n",
      "Epoch 43/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0065 - mae: 0.0465 - val_loss: 0.0098 - val_mae: 0.0562\n",
      "Epoch 44/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0054 - mae: 0.0395 - val_loss: 0.0098 - val_mae: 0.0584\n",
      "Epoch 45/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0061 - mae: 0.0441 - val_loss: 0.0127 - val_mae: 0.0680\n",
      "Epoch 46/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0083 - mae: 0.0500 - val_loss: 0.0221 - val_mae: 0.0764\n",
      "Epoch 47/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0090 - mae: 0.0580 - val_loss: 0.0138 - val_mae: 0.0659\n",
      "Epoch 48/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0104 - mae: 0.0556 - val_loss: 0.0093 - val_mae: 0.0604\n",
      "Epoch 49/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0094 - mae: 0.0532 - val_loss: 0.0138 - val_mae: 0.0694\n",
      "Epoch 50/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0100 - mae: 0.0629 - val_loss: 0.0103 - val_mae: 0.0578\n",
      "Epoch 51/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0072 - mae: 0.0480 - val_loss: 0.0103 - val_mae: 0.0644\n",
      "Epoch 52/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0068 - mae: 0.0536 - val_loss: 0.0102 - val_mae: 0.0604\n",
      "Epoch 53/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0068 - mae: 0.0460 - val_loss: 0.0104 - val_mae: 0.0615\n",
      "Epoch 54/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0059 - mae: 0.0490 - val_loss: 0.0134 - val_mae: 0.0643\n",
      "Epoch 55/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0102 - mae: 0.0520 - val_loss: 0.0098 - val_mae: 0.0613\n",
      "Epoch 56/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0061 - mae: 0.0482 - val_loss: 0.0108 - val_mae: 0.0633\n",
      "Epoch 57/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0049 - mae: 0.0398 - val_loss: 0.0104 - val_mae: 0.0604\n",
      "Epoch 58/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0047 - mae: 0.0412 - val_loss: 0.0109 - val_mae: 0.0593\n",
      "Epoch 58: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "(280, 1)\n",
      "Test RMSE: 497.139\n",
      "Test MAE: 297.643\n",
      "Test R2 Score:  0.7146922327935914\n",
      "MAPE 0.7815068375148831\n",
      "Test MBE 197.00339033497963\n",
      "nRMSE 0.9500050519951583\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "(69, 1)\n",
      "Test RMSE: 264.876\n",
      "Test MAE: 170.215\n",
      "Test R2 Score:  0.10674379106995568\n",
      "MAPE 1.9750164998249322\n",
      "Test MBE 118.60806558997352\n",
      "nRMSE 3.14738266588095\n",
      "MAE: [170.21511251296067, 170.21511251296067, 170.21511251296067, 170.21511251296067, 170.21511251296067, 170.21511251296067, 170.21511251296067, 170.21511251296067, 170.21511251296067, 170.21511251296067, 170.21511251296067, 170.21511251296067, 170.21511251296067, 170.21511251296067, 170.21511251296067, 170.21511251296067, 170.21511251296067, 170.21511251296067, 170.21511251296067, 170.21511251296067]\n",
      "RMSE: [264.87597742540294, 264.87597742540294, 264.87597742540294, 264.87597742540294, 264.87597742540294, 264.87597742540294, 264.87597742540294, 264.87597742540294, 264.87597742540294, 264.87597742540294, 264.87597742540294, 264.87597742540294, 264.87597742540294, 264.87597742540294, 264.87597742540294, 264.87597742540294, 264.87597742540294, 264.87597742540294, 264.87597742540294, 264.87597742540294]\n",
      "R^2: [0.10674379106995568, 0.10674379106995568, 0.10674379106995568, 0.10674379106995568, 0.10674379106995568, 0.10674379106995568, 0.10674379106995568, 0.10674379106995568, 0.10674379106995568, 0.10674379106995568, 0.10674379106995568, 0.10674379106995568, 0.10674379106995568, 0.10674379106995568, 0.10674379106995568, 0.10674379106995568, 0.10674379106995568, 0.10674379106995568, 0.10674379106995568, 0.10674379106995568]\n",
      "MAPE: [1.9750164998249322, 1.9750164998249322, 1.9750164998249322, 1.9750164998249322, 1.9750164998249322, 1.9750164998249322, 1.9750164998249322, 1.9750164998249322, 1.9750164998249322, 1.9750164998249322, 1.9750164998249322, 1.9750164998249322, 1.9750164998249322, 1.9750164998249322, 1.9750164998249322, 1.9750164998249322, 1.9750164998249322, 1.9750164998249322, 1.9750164998249322, 1.9750164998249322]\n",
      "MBE: [118.60806558997352, 118.60806558997352, 118.60806558997352, 118.60806558997352, 118.60806558997352, 118.60806558997352, 118.60806558997352, 118.60806558997352, 118.60806558997352, 118.60806558997352, 118.60806558997352, 118.60806558997352, 118.60806558997352, 118.60806558997352, 118.60806558997352, 118.60806558997352, 118.60806558997352, 118.60806558997352, 118.60806558997352, 118.60806558997352]\n",
      "nRMSE: [3.14738266588095, 3.14738266588095, 3.14738266588095, 3.14738266588095, 3.14738266588095, 3.14738266588095, 3.14738266588095, 3.14738266588095, 3.14738266588095, 3.14738266588095, 3.14738266588095, 3.14738266588095, 3.14738266588095, 3.14738266588095, 3.14738266588095, 3.14738266588095, 3.14738266588095, 3.14738266588095, 3.14738266588095, 3.14738266588095]\n",
      "Mean MAE: 170.2151125129607\n",
      "Mean RMSE: 264.875977425403\n",
      "Mean R^2: 0.10674379106995566\n",
      "Mean MAPE: 1.9750164998249322\n",
      "Mean MBE: 118.60806558997353\n",
      "Mean nRMSE: 3.1473826658809494\n"
     ]
    }
   ],
   "source": [
    "mae_list = []\n",
    "rmse_list = []\n",
    "r_square_list = []\n",
    "mape_list = []\n",
    "mbe_list = []\n",
    "nRMSE_list = []\n",
    "num_iterations = 20\n",
    "#num_iterations = 2\n",
    "for i in range(num_iterations):\n",
    "    # print(\"Shape of x_train:\", x_train.shape)\n",
    "    # print(\"Shape of y_train:\", y_train.shape)\n",
    "    # print(\"Shape of x_test:\", x_test.shape)\n",
    "    # print(\"Shape of y_test:\", y_test.shape)\n",
    "    model = createModel()\n",
    "    keras.config.disable_traceback_filtering()\n",
    "    fit_predict_stats(model)\n",
    "\n",
    "# sns.set_style(\"darkgrid\")\n",
    "# for true, hat in zip(true_values, predicted_values):\n",
    "#     plt.figure()\n",
    "#     plt.plot(true[1], color=\"green\")\n",
    "#     plt.plot(hat[1], color=\"red\")\n",
    "#     plt.savefig('plots/lstm_base_plot.png')\n",
    "    #plt.show()\n",
    "\n",
    "print(\"MAE:\", mae_list)\n",
    "print(\"RMSE:\", rmse_list)\n",
    "print(\"R^2:\", r_square_list)\n",
    "print(\"MAPE:\", mape_list)\n",
    "print(\"MBE:\", mbe_list)\n",
    "print(\"nRMSE:\", nRMSE_list)\n",
    "\n",
    "print(\"Mean MAE:\", np.mean(mae_list))\n",
    "print(\"Mean RMSE:\", np.mean(rmse_list))\n",
    "print(\"Mean R^2:\", np.mean(r_square_list))\n",
    "print(\"Mean MAPE:\", np.mean(mape_list))\n",
    "print(\"Mean MBE:\", np.mean(mbe_list))\n",
    "print(\"Mean nRMSE:\", np.mean(nRMSE_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Launching TensorBoard..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-289e65ac35f25f18\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-289e65ac35f25f18\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!rm -rf \"c:/work/Honours code/Transfer learning/LSTM/logs/\"\n",
    "#!rm -r \"c:/work/Honours code/Transfer learning/LSTM/logs/\"\n",
    "%load_ext tensorboard\n",
    "#%tensorboard --logdir LSTM/logs/\n",
    "%tensorboard --logdir  \"c:/work/Honours code/Transfer learning/LSTM/logs/\"\n",
    "#%tensorboard --logdir  \"./LSTM/logs/\"\n",
    "\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "#!kill 10060"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "Code credits to Xiaomin Chang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_training(params):\n",
    "    learning_rate = params['learning_rate']\n",
    "    lstm_units_1 = params['lstm_units_1']\n",
    "    lstm_units_2 = params['lstm_units_2']\n",
    "    lstm_units_3 = params['lstm_units_3']\n",
    "    batch_size = params['batch_size']\n",
    "    validation_split = params['validation_split']\n",
    "    \n",
    "    # create the model\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(lstm_units_1, activation='relu', return_sequences=True), input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Bidirectional(LSTM(lstm_units_2, activation='relu', return_sequences=True)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Bidirectional(LSTM(lstm_units_3, activation='relu', return_sequences=False)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=learning_rate), metrics=['mae'])\n",
    "\n",
    "    try:\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "        \n",
    "        history = model.fit(x_train, y_train, batch_size=batch_size, validation_data=(x_val, y_val))\n",
    "\n",
    "        print(history.history) \n",
    "    \n",
    "        #loss = history.history['val_loss'][-1]\n",
    "        loss = np.min(history.history['val_loss'])\n",
    "        return {'loss': loss, 'status': STATUS_OK}\n",
    "    except Exception as e:\n",
    "        print(\"Error: {}\".format(e))\n",
    "        print(\"Params: {}\".format(params))\n",
    "        return {'loss': float('inf'), 'status': STATUS_FAIL}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.0001), np.log(0.1)),\n",
    "    #'learning_rate': hp.choice('learning_rate', [0.001, 0.01, 0.1]),\n",
    "    'batch_size': hp.choice('batch_size', [32, 64, 128, 256]), \n",
    "    'lstm_units_1': hp.choice('lstm_units_1', [16, 32, 64]),\n",
    "    'lstm_units_2': hp.choice('lstm_units_2', [32, 64, 128]),\n",
    "    'lstm_units_3': hp.choice('lstm_units_3', [64, 128, 256]), \n",
    "    'validation_split': hp.uniform('validation_split', 0.1, 0.2),\n",
    "    'layer1_dropout': hp.uniform('layer1_dropout', 0.1, 0.5),\n",
    "    'layer2_dropout': hp.uniform('layer2_dropout', 0.1, 0.5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:16\u001b[0m 10s/step - loss: 0.0762 - mae: 0.1481\n",
      "\u001b[1m4/9\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0733 - mae: 0.1474 \n",
      "\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0636 - mae: 0.1327\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 183ms/step - loss: 0.0614 - mae: 0.1292 - val_loss: 0.0088 - val_mae: 0.0447\n",
      "\n",
      "{'loss': [0.05702084302902222], 'mae': [0.12263747304677963], 'val_loss': [0.008791370317339897], 'val_mae': [0.04465515539050102]}\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 12s/step - loss: 0.0591 - mae: 0.1192\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 614ms/step - loss: 0.5434 - mae: 0.4929 - val_loss: 0.0099 - val_mae: 0.0323\n",
      "\n",
      "{'loss': [0.6841548681259155], 'mae': [0.6023457050323486], 'val_loss': [0.009908531792461872], 'val_mae': [0.03230703994631767]}\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 9s/step - loss: 0.0711 - mae: 0.1337\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0641 - mae: 0.1277\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 721ms/step - loss: 0.0633 - mae: 0.1270 - val_loss: 0.0087 - val_mae: 0.0430\n",
      "\n",
      "{'loss': [0.060762662440538406], 'mae': [0.12502600252628326], 'val_loss': [0.008711587637662888], 'val_mae': [0.042951684445142746]}\n",
      "\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41\u001b[0m 13s/step - loss: 0.0515 - mae: 0.1108\n",
      "\u001b[1m3/9\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 6322.3867 - mae: 40.3268\n",
      "\u001b[1m5/9\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5841.8926 - mae: 37.2820\n",
      "\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 5179.2173 - mae: 33.0868\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 4633.4434 - mae: 29.6375\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 207ms/step - loss: 4430.2300 - mae: 28.3535 - val_loss: 0.0794 - val_mae: 0.2637\n",
      "\n",
      "{'loss': [2601.309814453125], 'mae': [16.797500610351562], 'val_loss': [0.07939893007278442], 'val_mae': [0.2636690139770508]}\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 9s/step - loss: 0.0453 - mae: 0.1076\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0498 - mae: 0.1189\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0510 - mae: 0.1241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 337ms/step - loss: 0.0511 - mae: 0.1254 - val_loss: 0.0146 - val_mae: 0.0999\n",
      "\n",
      "{'loss': [0.051697831600904465], 'mae': [0.1315559595823288], 'val_loss': [0.014604681171476841], 'val_mae': [0.099929578602314]}\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 10s/step - loss: 0.0686 - mae: 0.1331\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0607 - mae: 0.1277\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 718ms/step - loss: 0.0569 - mae: 0.1270 - val_loss: 0.0217 - val_mae: 0.1347\n",
      "\n",
      "{'loss': [0.053144969046115875], 'mae': [0.12626633048057556], 'val_loss': [0.021749049425125122], 'val_mae': [0.13468345999717712]}\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m50s\u001b[0m 13s/step - loss: 0.0581 - mae: 0.1045\n",
      "\u001b[1m2/5\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0625 - mae: 0.1154\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0603 - mae: 0.1158\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0585 - mae: 0.1181\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 342ms/step - loss: 0.0582 - mae: 0.1190 - val_loss: 0.0092 - val_mae: 0.0541\n",
      "\n",
      "{'loss': [0.05673619732260704], 'mae': [0.12357213348150253], 'val_loss': [0.009203624911606312], 'val_mae': [0.05412297695875168]}\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 10s/step - loss: 0.0621 - mae: 0.1294\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - loss: 0.0619 - mae: 0.1302 - val_loss: 0.0175 - val_mae: 0.1136\n",
      "\n",
      "{'loss': [0.06181168556213379], 'mae': [0.13058175146579742], 'val_loss': [0.01750219240784645], 'val_mae': [0.11363698542118073]}\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 10s/step - loss: 0.0749 - mae: 0.1390\n",
      "\u001b[1m2/5\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0637 - mae: 0.1425\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0585 - mae: 0.1423 \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0562 - mae: 0.1432\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 383ms/step - loss: 0.0532 - mae: 0.1437 - val_loss: 0.0137 - val_mae: 0.0949\n",
      "\n",
      "{'loss': [0.04718919098377228], 'mae': [0.14491163194179535], 'val_loss': [0.01372831966727972], 'val_mae': [0.09485043585300446]}\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 14s/step - loss: 0.0559 - mae: 0.1219\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - loss: 0.0556 - mae: 0.1225 - val_loss: 0.0117 - val_mae: 0.0807\n",
      "\n",
      "{'loss': [0.05544464290142059], 'mae': [0.12280518561601639], 'val_loss': [0.011726285330951214], 'val_mae': [0.0806538388133049]}\n",
      " 10%|█         | 10/100 [02:06<19:33, 13.04s/trial, best loss: 0.008711587637662888]WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x000001FC5AAEF1A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x000001FC5AAEF1A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 10s/step - loss: 0.0493 - mae: 0.1040\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0568 - mae: 0.1430\n",
      " 10%|█         | 10/100 [02:16<19:33, 13.04s/trial, best loss: 0.008711587637662888]WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x000001FC899D3E20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x000001FC899D3E20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 770ms/step - loss: 0.0595 - mae: 0.1610 - val_loss: 0.0089 - val_mae: 0.0549\n",
      "\n",
      "{'loss': [0.06230407580733299], 'mae': [0.17905281484127045], 'val_loss': [0.008933541364967823], 'val_mae': [0.054879531264305115]}\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 11s/step - loss: 0.0733 - mae: 0.1427\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0582 - mae: 0.1544\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 371ms/step - loss: 0.0556 - mae: 0.1525 - val_loss: 0.0255 - val_mae: 0.1389\n",
      "\n",
      "{'loss': [0.05031546205282211], 'mae': [0.14871200919151306], 'val_loss': [0.025462470948696136], 'val_mae': [0.13890640437602997]}\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 10s/step - loss: 0.0499 - mae: 0.1040\n",
      "\u001b[1m2/5\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0466 - mae: 0.1119\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0468 - mae: 0.1227\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - loss: 0.0467 - mae: 0.1393 - val_loss: 0.0116 - val_mae: 0.0831\n",
      "\n",
      "{'loss': [0.04621325433254242], 'mae': [0.1560308337211609], 'val_loss': [0.011613947339355946], 'val_mae': [0.083149753510952]}\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 9s/step - loss: 0.0664 - mae: 0.1394\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0618 - mae: 0.1353\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 667ms/step - loss: 0.0592 - mae: 0.1347 - val_loss: 0.0283 - val_mae: 0.1580\n",
      "\n",
      "{'loss': [0.05657769367098808], 'mae': [0.1341383159160614], 'val_loss': [0.028307819738984108], 'val_mae': [0.1579907387495041]}\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 10s/step - loss: 0.0622 - mae: 0.1255\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - loss: 70.0033 - mae: 1.9847 - val_loss: 0.0367 - val_mae: 0.1840\n",
      "\n",
      "{'loss': [104.9738998413086], 'mae': [2.914261817932129], 'val_loss': [0.03673308715224266], 'val_mae': [0.18404541909694672]}\n",
      "\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36\u001b[0m 12s/step - loss: 0.0146 - mae: 0.0620\n",
      "\u001b[1m3/9\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0351 - mae: 0.0907 \n",
      "\u001b[1m5/9\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0408 - mae: 0.0977\n",
      "\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0434 - mae: 0.1010\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0465 - mae: 0.1056\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 242ms/step - loss: 0.0479 - mae: 0.1077 - val_loss: 0.0089 - val_mae: 0.0385\n",
      "\n",
      "{'loss': [0.06053387001156807], 'mae': [0.12634147703647614], 'val_loss': [0.008860341273248196], 'val_mae': [0.03853107616305351]}\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 16s/step - loss: 0.0604 - mae: 0.1226\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - loss: 0.0636 - mae: 0.1337 - val_loss: 0.0110 - val_mae: 0.0767\n",
      "\n",
      "{'loss': [0.06513223052024841], 'mae': [0.13927657902240753], 'val_loss': [0.010955319739878178], 'val_mae': [0.0766659751534462]}\n",
      "\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:07\u001b[0m 16s/step - loss: 0.0819 - mae: 0.1429\n",
      "\u001b[1m3/9\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0806 - mae: 0.1464 \n",
      "\u001b[1m6/9\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0705 - mae: 0.1401\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0642 - mae: 0.1383\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 393ms/step - loss: 0.0629 - mae: 0.1382 - val_loss: 0.0196 - val_mae: 0.1253\n",
      "\n",
      "{'loss': [0.050976965576410294], 'mae': [0.13759437203407288], 'val_loss': [0.019642433151602745], 'val_mae': [0.12527920305728912]}\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:13\u001b[0m 18s/step - loss: 0.0637 - mae: 0.1296\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0598 - mae: 0.1347 \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0559 - mae: 0.1392\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 555ms/step - loss: 0.0549 - mae: 0.1406 - val_loss: 0.0252 - val_mae: 0.1479\n",
      "\n",
      "{'loss': [0.05003287270665169], 'mae': [0.14773420989513397], 'val_loss': [0.025242893025279045], 'val_mae': [0.1478891521692276]}\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 19s/step - loss: 0.0637 - mae: 0.1270\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - loss: 0.0612 - mae: 0.1240 - val_loss: 0.0088 - val_mae: 0.0496\n",
      "\n",
      "{'loss': [0.059978220611810684], 'mae': [0.12251985818147659], 'val_loss': [0.008806089870631695], 'val_mae': [0.04956769198179245]}\n",
      "\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:25\u001b[0m 33s/step - loss: 0.0821 - mae: 0.1548\n",
      "\u001b[1m3/9\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0739 - mae: 0.1442 \n",
      "\u001b[1m5/9\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0710 - mae: 0.1391\n",
      "\u001b[1m6/9\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0695 - mae: 0.1371\n",
      "\u001b[1m8/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0674 - mae: 0.1342\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 393ms/step - loss: 0.0659 - mae: 0.1323 - val_loss: 0.0089 - val_mae: 0.0390\n",
      "\n",
      "{'loss': [0.05998086929321289], 'mae': [0.12460945546627045], 'val_loss': [0.008855930529534817], 'val_mae': [0.0390310175716877]}\n",
      "\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:22\u001b[0m 25s/step - loss: 0.0444 - mae: 0.1159\n",
      "\u001b[1m3/9\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0440 - mae: 0.1149 \n",
      "\u001b[1m6/9\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0506 - mae: 0.1234\n",
      "\u001b[1m8/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0520 - mae: 0.1257\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 321ms/step - loss: 0.0521 - mae: 0.1264 - val_loss: 0.0110 - val_mae: 0.0765\n",
      "\n",
      "{'loss': [0.05281838774681091], 'mae': [0.12949006259441376], 'val_loss': [0.011045577935874462], 'val_mae': [0.076504647731781]}\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m43s\u001b[0m 22s/step - loss: 0.0514 - mae: 0.1217\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0537 - mae: 0.1208\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0570 - mae: 0.1236\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 0.0587 - mae: 0.1250 - val_loss: 0.0091 - val_mae: 0.0365\n",
      "\n",
      "{'loss': [0.06364618986845016], 'mae': [0.12919318675994873], 'val_loss': [0.009118681773543358], 'val_mae': [0.03653593361377716]}\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 21s/step - loss: 0.0530 - mae: 0.1155\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0590 - mae: 0.1222\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2s/step - loss: 0.0600 - mae: 0.1230 - val_loss: 0.0090 - val_mae: 0.0333\n",
      "\n",
      "{'loss': [0.060953568667173386], 'mae': [0.12382683157920837], 'val_loss': [0.008961725980043411], 'val_mae': [0.0332828015089035]}\n",
      "\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:01\u001b[0m 23s/step - loss: 0.0758 - mae: 0.1531\n",
      "\u001b[1m3/9\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0657 - mae: 0.1388 \n",
      "\u001b[1m6/9\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0563 - mae: 0.1244\n",
      "\u001b[1m8/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0551 - mae: 0.1243\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 329ms/step - loss: 0.0545 - mae: 0.1249 - val_loss: 0.0121 - val_mae: 0.0848\n",
      "\n",
      "{'loss': [0.0519120991230011], 'mae': [0.1275036334991455], 'val_loss': [0.012072565965354443], 'val_mae': [0.08475969731807709]}\n",
      "\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:04\u001b[0m 31s/step - loss: 0.0162 - mae: 0.0666\n",
      "\u001b[1m3/9\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0274 - mae: 0.0799 \n",
      "\u001b[1m4/9\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0302 - mae: 0.0847\n",
      "\u001b[1m6/9\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0352 - mae: 0.0936\n",
      "\u001b[1m8/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0391 - mae: 0.1015\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 539ms/step - loss: 0.0414 - mae: 0.1071 - val_loss: 0.0157 - val_mae: 0.1073\n",
      "\n",
      "{'loss': [0.050613030791282654], 'mae': [0.1294964700937271], 'val_loss': [0.015699826180934906], 'val_mae': [0.10734885931015015]}\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m45s\u001b[0m 23s/step - loss: 0.0518 - mae: 0.1067\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0592 - mae: 0.1196\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.0608 - mae: 0.1232 - val_loss: 0.0092 - val_mae: 0.0294\n",
      "\n",
      "{'loss': [0.06237025186419487], 'mae': [0.1267038881778717], 'val_loss': [0.009164806455373764], 'val_mae': [0.02937101386487484]}\n",
      "\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:01\u001b[0m 23s/step - loss: 0.0834 - mae: 0.1672\n",
      "\u001b[1m3/9\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0728 - mae: 0.1451 \n",
      "\u001b[1m5/9\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0702 - mae: 0.1420\n",
      "\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0672 - mae: 0.1390\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0644 - mae: 0.1371\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 423ms/step - loss: 0.0634 - mae: 0.1363 - val_loss: 0.0121 - val_mae: 0.0849\n",
      "\n",
      "{'loss': [0.05417980998754501], 'mae': [0.12979334592819214], 'val_loss': [0.012100059539079666], 'val_mae': [0.08491946011781693]}\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 22s/step - loss: 0.0680 - mae: 0.1345\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0666 - mae: 0.1325\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.0634 - mae: 0.1282 - val_loss: 0.0090 - val_mae: 0.0341\n",
      "\n",
      "{'loss': [0.06027740240097046], 'mae': [0.12389158457517624], 'val_loss': [0.009027217514812946], 'val_mae': [0.03409142792224884]}\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 22s/step - loss: 0.0529 - mae: 0.1129\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 48176504832.0000 - mae: 98991.7109\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 68135342080.0000 - mae: 140002.9375 - val_loss: 0.0267 - val_mae: 0.1170\n",
      "\n",
      "{'loss': [88094179328.0], 'mae': [181014.171875], 'val_loss': [0.026705587282776833], 'val_mae': [0.11702419072389603]}\n",
      "\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:38\u001b[0m 35s/step - loss: 0.0588 - mae: 0.1313\n",
      "\u001b[1m4/9\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0570 - mae: 0.1330 \n",
      "\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0507 - mae: 0.1320\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 345ms/step - loss: 0.0479 - mae: 0.1340 - val_loss: 0.0250 - val_mae: 0.1400\n",
      "\n",
      "{'loss': [0.042010899633169174], 'mae': [0.1404961198568344], 'val_loss': [0.025024857372045517], 'val_mae': [0.14000092446804047]}\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m46s\u001b[0m 23s/step - loss: 0.0712 - mae: 0.1305\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0656 - mae: 0.1293\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.0609 - mae: 0.1267 - val_loss: 0.0124 - val_mae: 0.0853\n",
      "\n",
      "{'loss': [0.056082893162965775], 'mae': [0.12410672008991241], 'val_loss': [0.01237131655216217], 'val_mae': [0.08530718088150024]}\n",
      "\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:03\u001b[0m 23s/step - loss: 0.0626 - mae: 0.1128\n",
      "\u001b[1m3/9\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0620 - mae: 0.1158 \n",
      "\u001b[1m6/9\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0577 - mae: 0.1139\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0569 - mae: 0.1158\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 430ms/step - loss: 0.0569 - mae: 0.1165 - val_loss: 0.0087 - val_mae: 0.0453\n",
      "\n",
      "{'loss': [0.05693882331252098], 'mae': [0.1231561005115509], 'val_loss': [0.00872783176600933], 'val_mae': [0.04528823494911194]}\n",
      "\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:59\u001b[0m 22s/step - loss: 0.0436 - mae: 0.0941\n",
      "\u001b[1m4/9\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0487 - mae: 0.1082 \n",
      "\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0482 - mae: 0.1117\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0489 - mae: 0.1150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 366ms/step - loss: 0.0492 - mae: 0.1161 - val_loss: 0.0132 - val_mae: 0.0908\n",
      "\n",
      "{'loss': [0.0515945740044117], 'mae': [0.1262894868850708], 'val_loss': [0.013179266825318336], 'val_mae': [0.09083843231201172]}\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 22s/step - loss: 0.0654 - mae: 0.1230\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0621 - mae: 0.1225\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 0.0616 - mae: 0.1225 - val_loss: 0.0089 - val_mae: 0.0341\n",
      "\n",
      "{'loss': [0.06012094393372536], 'mae': [0.12252265214920044], 'val_loss': [0.008867698721587658], 'val_mae': [0.03405323252081871]}\n",
      "\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:39\u001b[0m 42s/step - loss: 0.0736 - mae: 0.1495\n",
      "\u001b[1m4/9\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0593 - mae: 0.1334 \n",
      "\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0528 - mae: 0.1307\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0514 - mae: 0.1328\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 433ms/step - loss: 0.0509 - mae: 0.1337 - val_loss: 0.0278 - val_mae: 0.1572\n",
      "\n",
      "{'loss': [0.046867549419403076], 'mae': [0.14200033247470856], 'val_loss': [0.02779359370470047], 'val_mae': [0.15723219513893127]}\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m48s\u001b[0m 24s/step - loss: 0.0807 - mae: 0.1419\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0717 - mae: 0.1342\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - loss: 0.0654 - mae: 0.1289 - val_loss: 0.0089 - val_mae: 0.0376\n",
      "\n",
      "{'loss': [0.05910877510905266], 'mae': [0.12348172068595886], 'val_loss': [0.008909263648092747], 'val_mae': [0.03755715861916542]}\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 24s/step - loss: 0.0600 - mae: 0.1185\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3s/step - loss: 0.0607 - mae: 0.1218 - val_loss: 0.0091 - val_mae: 0.0340\n",
      "\n",
      "{'loss': [0.06105473265051842], 'mae': [0.12351588159799576], 'val_loss': [0.009136660024523735], 'val_mae': [0.03404929116368294]}\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:42\u001b[0m 26s/step - loss: 0.0581 - mae: 0.1188\n",
      "\u001b[1m2/5\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0576 - mae: 0.1269 \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0575 - mae: 0.1367\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0552 - mae: 0.1462\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 868ms/step - loss: 0.0545 - mae: 0.1485 - val_loss: 0.0123 - val_mae: 0.0881\n",
      "\n",
      "{'loss': [0.05089331045746803], 'mae': [0.15975086390972137], 'val_loss': [0.012254332192242146], 'val_mae': [0.08807770907878876]}\n",
      "\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:31\u001b[0m 26s/step - loss: 0.0710 - mae: 0.1261\n",
      "\u001b[1m3/9\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0621 - mae: 0.1195 \n",
      "\u001b[1m4/9\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0601 - mae: 0.1213\n",
      "\u001b[1m5/9\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0582 - mae: 0.1223\n",
      "\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0556 - mae: 0.1257\n",
      "\u001b[1m8/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0546 - mae: 0.1273\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 407ms/step - loss: 0.0529 - mae: 0.1298 - val_loss: 0.0249 - val_mae: 0.1467\n",
      "\n",
      "{'loss': [0.046501923352479935], 'mae': [0.1400812566280365], 'val_loss': [0.024924172088503838], 'val_mae': [0.14666268229484558]}\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m46s\u001b[0m 23s/step - loss: 0.0606 - mae: 0.1309\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.9771 - mae: 0.5780\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2s/step - loss: 1.3548 - mae: 0.7615 - val_loss: 0.0099 - val_mae: 0.0319\n",
      "\n",
      "{'loss': [1.7325419187545776], 'mae': [0.9450442790985107], 'val_loss': [0.009875685907900333], 'val_mae': [0.031938012689352036]}\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:57\u001b[0m 44s/step - loss: 0.0766 - mae: 0.1454\n",
      "\u001b[1m2/5\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0715 - mae: 0.1375 \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0657 - mae: 0.1296\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 926ms/step - loss: 0.0635 - mae: 0.1272 - val_loss: 0.0089 - val_mae: 0.0349\n",
      "\n",
      "{'loss': [0.05895126238465309], 'mae': [0.12246740609407425], 'val_loss': [0.008881589397788048], 'val_mae': [0.03487090393900871]}\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m48s\u001b[0m 24s/step - loss: 0.0479 - mae: 0.1010\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0506 - mae: 0.1115\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2s/step - loss: 0.0523 - mae: 0.1186 - val_loss: 0.0182 - val_mae: 0.1192\n",
      "\n",
      "{'loss': [0.05394962802529335], 'mae': [0.12562274932861328], 'val_loss': [0.01819983869791031], 'val_mae': [0.11924514919519424]}\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 25s/step - loss: 0.0555 - mae: 0.1212\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0574 - mae: 0.1245\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3s/step - loss: 0.0580 - mae: 0.1256 - val_loss: 0.0497 - val_mae: 0.2167\n",
      "\n",
      "{'loss': [0.059333983808755875], 'mae': [0.12777619063854218], 'val_loss': [0.04969276860356331], 'val_mae': [0.21669118106365204]}\n",
      "\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:52\u001b[0m 29s/step - loss: 0.0541 - mae: 0.1308\n",
      "\u001b[1m4/9\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0540 - mae: 0.1335 \n",
      "\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0519 - mae: 0.1418\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0513 - mae: 0.1452\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 436ms/step - loss: 0.0510 - mae: 0.1462 - val_loss: 0.0156 - val_mae: 0.1077\n",
      "\n",
      "{'loss': [0.04807676747441292], 'mae': [0.15525837242603302], 'val_loss': [0.015633970499038696], 'val_mae': [0.1076963022351265]}\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50\u001b[0m 28s/step - loss: 0.0519 - mae: 0.1222\n",
      "\u001b[1m2/5\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.1152 - mae: 0.2220\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.1210 - mae: 0.2331\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.1192 - mae: 0.2296 \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 990ms/step - loss: 0.1166 - mae: 0.2234 - val_loss: 0.0096 - val_mae: 0.0280\n",
      "\n",
      "{'loss': [0.11147136241197586], 'mae': [0.21118037402629852], 'val_loss': [0.009638524614274502], 'val_mae': [0.028042083606123924]}\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m52s\u001b[0m 26s/step - loss: 0.0639 - mae: 0.1265\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0599 - mae: 0.1225\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2s/step - loss: 0.0596 - mae: 0.1226 - val_loss: 0.0088 - val_mae: 0.0381\n",
      "\n",
      "{'loss': [0.058775417506694794], 'mae': [0.12284236401319504], 'val_loss': [0.008837215602397919], 'val_mae': [0.03814656287431717]}\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m43s\u001b[0m 44s/step - loss: 0.0600 - mae: 0.1227\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0600 - mae: 0.1229\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 4s/step - loss: 0.0600 - mae: 0.1229 - val_loss: 0.0106 - val_mae: 0.0726\n",
      "\n",
      "{'loss': [0.05997520312666893], 'mae': [0.12307918816804886], 'val_loss': [0.010562014766037464], 'val_mae': [0.07255873084068298]}\n",
      "\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:46\u001b[0m 28s/step - loss: 0.0271 - mae: 0.0578\n",
      "\u001b[1m2/9\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0479 - mae: 0.0953 \n",
      "\u001b[1m4/9\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0551 - mae: 0.1145\n",
      "\u001b[1m5/9\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0556 - mae: 0.1198\n",
      "\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0546 - mae: 0.1261\n",
      "\u001b[1m8/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0536 - mae: 0.1280\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0528 - mae: 0.1299\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 534ms/step - loss: 0.0522 - mae: 0.1314 - val_loss: 0.0222 - val_mae: 0.1363\n",
      "\n",
      "{'loss': [0.0468386709690094], 'mae': [0.1446828693151474], 'val_loss': [0.02219962142407894], 'val_mae': [0.13630202412605286]}\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:56\u001b[0m 29s/step - loss: 0.0497 - mae: 0.1050\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5895 - mae: 0.4689 \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.5617 - mae: 0.4550\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 853ms/step - loss: 0.5508 - mae: 0.4485 - val_loss: 0.0107 - val_mae: 0.0426\n",
      "\n",
      "{'loss': [0.49669113755226135], 'mae': [0.4158993661403656], 'val_loss': [0.010669159702956676], 'val_mae': [0.042606085538864136]}\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m51s\u001b[0m 26s/step - loss: 0.0611 - mae: 0.1217\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0628 - mae: 0.1244\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2s/step - loss: 0.0619 - mae: 0.1240 - val_loss: 0.0092 - val_mae: 0.0311\n",
      "\n",
      "{'loss': [0.06098141521215439], 'mae': [0.12361183017492294], 'val_loss': [0.009153477847576141], 'val_mae': [0.031074728816747665]}\n",
      "\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:24\u001b[0m 26s/step - loss: 0.0577 - mae: 0.1240\n",
      "\u001b[1m4/9\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0568 - mae: 0.1258 \n",
      "\u001b[1m8/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0546 - mae: 0.1301\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 479ms/step - loss: 0.0536 - mae: 0.1318 - val_loss: 0.0218 - val_mae: 0.1335\n",
      "\n",
      "{'loss': [0.049715738743543625], 'mae': [0.13828839361667633], 'val_loss': [0.021805178374052048], 'val_mae': [0.13350777328014374]}\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 27s/step - loss: 0.0596 - mae: 0.1213\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0592 - mae: 0.1216\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3s/step - loss: 0.0591 - mae: 0.1217 - val_loss: 0.0121 - val_mae: 0.0843\n",
      "\n",
      "{'loss': [0.05881460756063461], 'mae': [0.1219009980559349], 'val_loss': [0.012107335031032562], 'val_mae': [0.08428219705820084]}\n",
      "\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:54\u001b[0m 29s/step - loss: 0.0899 - mae: 0.1570\n",
      "\u001b[1m2/9\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0881 - mae: 0.1588 \n",
      "\u001b[1m4/9\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0801 - mae: 0.1524\n",
      "\u001b[1m6/9\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0773 - mae: 0.1495\n",
      "\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0751 - mae: 0.1472\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0710 - mae: 0.1430\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 491ms/step - loss: 0.0694 - mae: 0.1415 - val_loss: 0.0102 - val_mae: 0.0689\n",
      "\n",
      "{'loss': [0.05520728975534439], 'mae': [0.12744566798210144], 'val_loss': [0.01018531247973442], 'val_mae': [0.06893932819366455]}\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35\u001b[0m 48s/step - loss: 0.0570 - mae: 0.1222\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0575 - mae: 0.1272 \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step - loss: 0.0562 - mae: 0.1289 - val_loss: 0.0201 - val_mae: 0.1255\n",
      "\n",
      "{'loss': [0.05484320968389511], 'mae': [0.13059207797050476], 'val_loss': [0.020098976790905], 'val_mae': [0.12549403309822083]}\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:52\u001b[0m 28s/step - loss: 0.0724 - mae: 0.1431\n",
      "\u001b[1m2/5\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0595 - mae: 0.1374 \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0574 - mae: 0.1413\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0549 - mae: 0.1436\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0532 - mae: 0.1447\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 982ms/step - loss: 0.0521 - mae: 0.1455 - val_loss: 0.0135 - val_mae: 0.0955\n",
      "\n",
      "{'loss': [0.04648591950535774], 'mae': [0.14929071068763733], 'val_loss': [0.013485388830304146], 'val_mae': [0.09553113579750061]}\n",
      "\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:44\u001b[0m 28s/step - loss: 0.0144 - mae: 0.0484\n",
      "\u001b[1m3/9\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0330 - mae: 0.1076 \n",
      "\u001b[1m4/9\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0372 - mae: 0.1156\n",
      "\u001b[1m6/9\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0413 - mae: 0.1213\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0439 - mae: 0.1261\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 567ms/step - loss: 0.0444 - mae: 0.1273 - val_loss: 0.0439 - val_mae: 0.1989\n",
      "\n",
      "{'loss': [0.04861869290471077], 'mae': [0.13809500634670258], 'val_loss': [0.04386061057448387], 'val_mae': [0.19894888997077942]}\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m48s\u001b[0m 24s/step - loss: 0.0526 - mae: 0.1085\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0574 - mae: 0.1170\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2s/step - loss: 0.0595 - mae: 0.1214 - val_loss: 0.0091 - val_mae: 0.0278\n",
      "\n",
      "{'loss': [0.06164111942052841], 'mae': [0.1258682906627655], 'val_loss': [0.009090612642467022], 'val_mae': [0.027787532657384872]}\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 26s/step - loss: 0.0638 - mae: 0.1279\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 20028569600.0000 - mae: 27101.1387\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3s/step - loss: 26704758784.0000 - mae: 36134.8086 - val_loss: 83308.0469 - val_mae: 287.1533\n",
      "\n",
      "{'loss': [40057139200.0], 'mae': [54202.1484375], 'val_loss': [83308.046875], 'val_mae': [287.15325927734375]}\n",
      "\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:48\u001b[0m 29s/step - loss: 0.0718 - mae: 0.1413\n",
      "\u001b[1m3/9\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0640 - mae: 0.1388 \n",
      "\u001b[1m6/9\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0545 - mae: 0.1295\n",
      "\u001b[1m8/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0526 - mae: 0.1296\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 558ms/step - loss: 0.0516 - mae: 0.1308 - val_loss: 0.0183 - val_mae: 0.1196\n",
      "\n",
      "{'loss': [0.04781205579638481], 'mae': [0.13543926179409027], 'val_loss': [0.01829528622329235], 'val_mae': [0.11963970959186554]}\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m51s\u001b[0m 26s/step - loss: 0.0664 - mae: 0.1246\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0624 - mae: 0.1244\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2s/step - loss: 0.0596 - mae: 0.1244 - val_loss: 0.0130 - val_mae: 0.0893\n",
      "\n",
      "{'loss': [0.0567985475063324], 'mae': [0.12444929033517838], 'val_loss': [0.013014424592256546], 'val_mae': [0.08926966786384583]}\n",
      "\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:52\u001b[0m 44s/step - loss: 0.0417 - mae: 0.1026\n",
      "\u001b[1m4/9\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0484 - mae: 0.1076 \n",
      "\u001b[1m8/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0532 - mae: 0.1174\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 512ms/step - loss: 0.0539 - mae: 0.1187 - val_loss: 0.0088 - val_mae: 0.0424\n",
      "\n",
      "{'loss': [0.056802596896886826], 'mae': [0.12362044304609299], 'val_loss': [0.008809821680188179], 'val_mae': [0.04239330440759659]}\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35\u001b[0m 24s/step - loss: 0.0723 - mae: 0.1563\n",
      "\u001b[1m2/5\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0700 - mae: 0.1489\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0659 - mae: 0.1416 \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0635 - mae: 0.1381\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 815ms/step - loss: 0.0608 - mae: 0.1346 - val_loss: 0.0108 - val_mae: 0.0741\n",
      "\n",
      "{'loss': [0.055266790091991425], 'mae': [0.12740130722522736], 'val_loss': [0.010826132260262966], 'val_mae': [0.07413456588983536]}\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m45s\u001b[0m 23s/step - loss: 0.0512 - mae: 0.1048\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0582 - mae: 0.1193\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.0585 - mae: 0.1203 - val_loss: 0.0090 - val_mae: 0.0326\n",
      "\n",
      "{'loss': [0.059423867613077164], 'mae': [0.12338169664144516], 'val_loss': [0.009017383679747581], 'val_mae': [0.03263421729207039]}\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 27s/step - loss: 0.0618 - mae: 0.1274\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - loss: 0.0610 - mae: 0.1275 - val_loss: 0.0234 - val_mae: 0.1399\n",
      "\n",
      "{'loss': [0.06065700948238373], 'mae': [0.12749163806438446], 'val_loss': [0.023441122844815254], 'val_mae': [0.13994775712490082]}\n",
      "\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:23\u001b[0m 25s/step - loss: 0.0376 - mae: 0.1108\n",
      "\u001b[1m3/9\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0452 - mae: 0.1160 \n",
      "\u001b[1m5/9\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0462 - mae: 0.1162\n",
      "\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0476 - mae: 0.1166\n",
      "\u001b[1m8/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0494 - mae: 0.1181\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0508 - mae: 0.1192\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 452ms/step - loss: 0.0519 - mae: 0.1201 - val_loss: 0.0090 - val_mae: 0.0332\n",
      "\n",
      "{'loss': [0.06162514537572861], 'mae': [0.12815974652767181], 'val_loss': [0.008983418345451355], 'val_mae': [0.03316138684749603]}\n",
      "\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:40\u001b[0m 28s/step - loss: 0.0448 - mae: 0.1130\n",
      "\u001b[1m2/9\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0500 - mae: 0.1237 \n",
      "\u001b[1m4/9\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0532 - mae: 0.1257\n",
      "\u001b[1m6/9\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0580 - mae: 0.1294\n",
      "\u001b[1m8/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0586 - mae: 0.1295\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0585 - mae: 0.1294\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - loss: 0.0585 - mae: 0.1294 - val_loss: 0.0095 - val_mae: 0.0620\n",
      "\n",
      "{'loss': [0.05813699588179588], 'mae': [0.12913084030151367], 'val_loss': [0.00954442098736763], 'val_mae': [0.06195814162492752]}\n",
      "\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:08\u001b[0m 31s/step - loss: 0.0849 - mae: 0.1793\n",
      "\u001b[1m2/9\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0736 - mae: 0.1619 \n",
      "\u001b[1m4/9\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0663 - mae: 0.1493\n",
      "\u001b[1m5/9\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0662 - mae: 0.1476\n",
      "\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0644 - mae: 0.1428\n",
      "\u001b[1m8/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0632 - mae: 0.1404\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0624 - mae: 0.1389\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 556ms/step - loss: 0.0618 - mae: 0.1376 - val_loss: 0.0093 - val_mae: 0.0553\n",
      "\n",
      "{'loss': [0.05631218105554581], 'mae': [0.1264830380678177], 'val_loss': [0.009267192333936691], 'val_mae': [0.05531315878033638]}\n",
      "\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:19\u001b[0m 32s/step - loss: 0.0682 - mae: 0.1388\n",
      "\u001b[1m2/9\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0732 - mae: 0.1428 \n",
      "\u001b[1m4/9\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0687 - mae: 0.1386\n",
      "\u001b[1m5/9\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0671 - mae: 0.1369\n",
      "\u001b[1m6/9\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0652 - mae: 0.1350\n",
      "\u001b[1m8/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0632 - mae: 0.1340\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0622 - mae: 0.1334\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 509ms/step - loss: 0.0613 - mae: 0.1329 - val_loss: 0.0114 - val_mae: 0.0806\n",
      "\n",
      "{'loss': [0.053664207458496094], 'mae': [0.12865561246871948], 'val_loss': [0.01144285686314106], 'val_mae': [0.08063089847564697]}\n",
      "\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:57\u001b[0m 30s/step - loss: 0.0476 - mae: 0.1000\n",
      "\u001b[1m2/9\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 3s/step - loss: 0.0591 - mae: 0.1113  \n",
      "\u001b[1m3/9\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 1s/step - loss: 0.0619 - mae: 0.1167 \n",
      "\u001b[1m5/9\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 738ms/step - loss: 0.0646 - mae: 0.1245\n",
      "\u001b[1m6/9\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 607ms/step - loss: 0.0636 - mae: 0.1244\n",
      "\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 522ms/step - loss: 0.0633 - mae: 0.1255\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - loss: 0.0617 - mae: 0.1258\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 851ms/step - loss: 0.0612 - mae: 0.1259 - val_loss: 0.0101 - val_mae: 0.0666\n",
      "\n",
      "{'loss': [0.05590817332267761], 'mae': [0.12724944949150085], 'val_loss': [0.010125449858605862], 'val_mae': [0.06655769795179367]}\n",
      "\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:38\u001b[0m 50s/step - loss: 0.0835 - mae: 0.1496\n",
      "\u001b[1m2/9\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0824 - mae: 0.1467 \n",
      "\u001b[1m4/9\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0736 - mae: 0.1365\n",
      "\u001b[1m5/9\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0721 - mae: 0.1356\n",
      "\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0678 - mae: 0.1318\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0654 - mae: 0.1303\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 479ms/step - loss: 0.0645 - mae: 0.1297 - val_loss: 0.0089 - val_mae: 0.0521\n",
      "\n",
      "{'loss': [0.05675812438130379], 'mae': [0.12485767155885696], 'val_loss': [0.008942424319684505], 'val_mae': [0.052127063274383545]}\n",
      "\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:07\u001b[0m 23s/step - loss: 0.0899 - mae: 0.1624\n",
      "\u001b[1m2/9\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0761 - mae: 0.1479 \n",
      "\u001b[1m3/9\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0687 - mae: 0.1414\n",
      "\u001b[1m5/9\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0605 - mae: 0.1336\n",
      "\u001b[1m6/9\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0590 - mae: 0.1336\n",
      "\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0578 - mae: 0.1339\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0557 - mae: 0.1348\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 537ms/step - loss: 0.0549 - mae: 0.1351 - val_loss: 0.0221 - val_mae: 0.1368\n",
      "\n",
      "{'loss': [0.04732659459114075], 'mae': [0.13785049319267273], 'val_loss': [0.022108260542154312], 'val_mae': [0.1368257701396942]}\n",
      "\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:36\u001b[0m 27s/step - loss: 0.0876 - mae: 0.1541\n",
      "\u001b[1m2/9\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0795 - mae: 0.1442 \n",
      "\u001b[1m4/9\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0645 - mae: 0.1268\n",
      "\u001b[1m6/9\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0591 - mae: 0.1237\n",
      "\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0567 - mae: 0.1227\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0547 - mae: 0.1243\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 480ms/step - loss: 0.0540 - mae: 0.1250 - val_loss: 0.0236 - val_mae: 0.1425\n",
      "\n",
      "{'loss': [0.047540608793497086], 'mae': [0.13141758739948273], 'val_loss': [0.02361328899860382], 'val_mae': [0.14245469868183136]}\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m56s\u001b[0m 28s/step - loss: 0.0633 - mae: 0.1267\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0608 - mae: 0.1232\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - loss: 0.0612 - mae: 0.1238 - val_loss: 0.0092 - val_mae: 0.0289\n",
      "\n",
      "{'loss': [0.06153339147567749], 'mae': [0.12438385933637619], 'val_loss': [0.0091977808624506], 'val_mae': [0.028935998678207397]}\n",
      "\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:08\u001b[0m 24s/step - loss: 0.0246 - mae: 0.0739\n",
      "\u001b[1m3/9\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0407 - mae: 0.1032 \n",
      "\u001b[1m4/9\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0396 - mae: 0.1036\n",
      "\u001b[1m5/9\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0413 - mae: 0.1071\n",
      "\u001b[1m6/9\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0429 - mae: 0.1107\n",
      "\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0437 - mae: 0.1132\n",
      "\u001b[1m8/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0440 - mae: 0.1151\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0446 - mae: 0.1172\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 411ms/step - loss: 0.0450 - mae: 0.1189 - val_loss: 0.0211 - val_mae: 0.1317\n",
      "\n",
      "{'loss': [0.04914778843522072], 'mae': [0.13447649776935577], 'val_loss': [0.021109048277139664], 'val_mae': [0.13171537220478058]}\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m50s\u001b[0m 25s/step - loss: 0.0761 - mae: 0.1467\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0670 - mae: 0.1327\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2s/step - loss: 0.0658 - mae: 0.1310 - val_loss: 0.0092 - val_mae: 0.0276\n",
      "\n",
      "{'loss': [0.06239587813615799], 'mae': [0.12598051130771637], 'val_loss': [0.009219343774020672], 'val_mae': [0.02759937196969986]}\n",
      " 76%|███████▌  | 76/100 [34:50<12:34, 31.42s/trial, best loss: 0.008711587637662888]"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "algo = partial(tpe.suggest, n_startup_jobs=20)\n",
    "best = fmin(lstm_training, param_grid, algo=algo, max_evals=100, pass_expr_memo_ctrl=None, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 256, 'layer1_dropout': 0.44393371319012737, 'layer2_dropout': 0.45138937440794225, 'learning_rate': 0.00021780192577236987, 'lstm_units_1': 16, 'lstm_units_2': 128, 'lstm_units_3': 64, 'validation_split': 0.12182995253284896}\n"
     ]
    }
   ],
   "source": [
    "best_hps = space_eval(param_grid, best)\n",
    "print(best_hps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
